{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colab_intro",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 2: 텍스트 청킹 기법 실습 (예제)\n",
    "\n",
    "이 노트북은 다양한 청킹 전략을 예제로 실습하며 장단점과 적용 맥락을 빠르게 파악할 수 있도록 구성되어 있습니다.\n",
    "\n",
    "## 📚 학습 목표\n",
    "- 대표적 청킹 전략(고정 길이/슬라이딩/구조/계층)의 개념과 차이 이해\n",
    "- 간단한 예문으로 각 기법을 직접 실행해 결과 비교\n",
    "- 과/소청킹 현상과 문맥 보존의 트레이드오프 체감\n",
    "\n",
    "## 📋 실습 구성\n",
    "- 1️⃣ 환경 설정: Colab 드라이브 마운트 및 경로 설정\n",
    "- 2️⃣ 고정 길이 청킹: 문장/단어 단위 고정 크기 분할\n",
    "- 3️⃣ 슬라이딩 윈도우: 겹침 비율을 조절하며 중복 문맥 유지\n",
    "- 4️⃣ 구조 기반: 마크다운 헤더/코드블록 경계를 활용한 분할\n",
    "- 5️⃣ 계층 기반: 섹션 제목을 헤더로 포함해 상하위 맥락 유지\n",
    "\n",
    "> ⚠️ 실습 셀 실행 전, 환경 설정 셀(1️⃣)을 먼저 실행하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9c87b",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣ Google Colab 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Google Colab 환경 설정\n",
    "# ========================================\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Google Drive 마운트\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 경로 설정\n",
    "BASE_DIR = \"/content/drive/MyDrive/ostep_rag\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "\n",
    "print(\"✅ Colab 환경 설정 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d9401",
   "metadata": {},
   "source": [
    "\n",
    "# 텍스트 청킹 실습 노트북\n",
    "\n",
    "이 노트북은 **고정 길이**, **슬라이딩 윈도우**, **의미 기반**, **구조 기반**, **계층 구조** 등 5가지 청킹 전략을 각각의 셀로 실습할 수 있도록 구성되어 있습니다.  \n",
    "각 섹션에는 (1) 설명, (2) 예문, (3) 실행 코드가 포함되어 있습니다.\n",
    "\n",
    "> 팁: 각 셀을 위에서부터 순서대로 실행하세요. 결과는 `chunks` 리스트 혹은 표 형태로 출력됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca42f7a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 2️⃣ 고정 길이 청킹 (Fixed-length)\n",
    "\n",
    "**개념**: 문서를 일정한 단위(문장/단어/문자)로 **균등하게** 나눕니다.  \n",
    "**장점**: 구현이 단순하고 빠르며 병렬 처리에 유리.  \n",
    "**단점**: 문맥이 끊기거나 질의와 무관한 정보가 포함될 수 있음.\n",
    "\n",
    "아래 예문은 문장 3개씩 고정 길이로 분할합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7297a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fixed-length chunking by sentences (3 sentences per chunk) ===\n",
      "[1] Machine learning is a subset of artificial intelligence. It focuses on algorithms that can learn from data. The goal is to make predictions or decisions without being explicitly programmed.\n",
      "\n",
      "[2] There are three main types of machine learning. Supervised learning uses labeled training data. Unsupervised learning finds patterns in unlabeled data.\n",
      "\n",
      "[3] Reinforcement learning learns through trial and error. Deep learning is a subset of machine learning. It uses neural networks with multiple layers.\n",
      "\n",
      "[4] These networks can learn complex patterns in data. They have been very successful in image recognition and natural language processing.\n",
      "\n",
      "=== Fixed-length chunking by words (15 words per chunk) ===\n",
      "[1] Machine learning is a subset of artificial intelligence. It focuses on algorithms that can learn\n",
      "\n",
      "[2] from data. The goal is to make predictions or decisions without being explicitly programmed. There\n",
      "\n",
      "[3] are three main types of machine learning. Supervised learning uses labeled training data. Unsupervised learning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "def simple_sent_split(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into sentences using simple rules.\n",
    "    - Split on periods, question marks, exclamation marks\n",
    "    - Split on line breaks\n",
    "    \"\"\"\n",
    "    # First split by line breaks\n",
    "    parts = re.split(r\"\\n+\", text.strip())\n",
    "    sentences = []\n",
    "    \n",
    "    for part in parts:\n",
    "        # Split on punctuation marks\n",
    "        split_sentences = re.split(r\"(?<=[\\.!\\?])\\s+\", part.strip())\n",
    "        # Filter out empty strings\n",
    "        split_sentences = [s for s in split_sentences if s]\n",
    "        sentences.extend(split_sentences)\n",
    "    \n",
    "    # Clean up: remove extra whitespace\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def chunk_by_fixed_length(text: str, unit: str = \"sentences\", size: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Fixed-length chunking: Split text into equal-sized chunks.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to chunk\n",
    "        unit: \"sentences\", \"words\", or \"chars\"\n",
    "        size: Number of units per chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    # Step 1: Split text into basic units\n",
    "    if unit == \"sentences\":\n",
    "        items = simple_sent_split(text)\n",
    "    elif unit == \"words\":\n",
    "        # Split on whitespace to get words\n",
    "        items = re.findall(r\"\\S+\", text)\n",
    "    elif unit == \"chars\":\n",
    "        # Split into individual characters\n",
    "        items = list(text)\n",
    "    else:\n",
    "        raise ValueError(\"unit must be one of: sentences, words, chars\")\n",
    "\n",
    "    # Step 2: Group items into chunks of specified size\n",
    "    chunks = []\n",
    "    for i in range(0, len(items), size):\n",
    "        # Get a slice of items for this chunk\n",
    "        chunk_items = items[i:i+size]\n",
    "        \n",
    "        # Join items back into text\n",
    "        if unit == \"sentences\":\n",
    "            chunks.append(\" \".join(chunk_items))\n",
    "        elif unit == \"words\":\n",
    "            chunks.append(\" \".join(chunk_items))\n",
    "        else:  # chars\n",
    "            chunks.append(\"\".join(chunk_items))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def show_chunks(chunks):\n",
    "    \"\"\"Display chunks in a numbered format\"\"\"\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"[{i}] {chunk}\\n\")\n",
    "\n",
    "# Example: Let's chunk a simple text about machine learning\n",
    "text = \"\"\"\n",
    "Machine learning is a subset of artificial intelligence. It focuses on algorithms that can learn from data. The goal is to make predictions or decisions without being explicitly programmed.\n",
    "There are three main types of machine learning. Supervised learning uses labeled training data. Unsupervised learning finds patterns in unlabeled data. Reinforcement learning learns through trial and error.\n",
    "Deep learning is a subset of machine learning. It uses neural networks with multiple layers. These networks can learn complex patterns in data. They have been very successful in image recognition and natural language processing.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Fixed-length chunking by sentences (3 sentences per chunk) ===\")\n",
    "chunks = chunk_by_fixed_length(text, unit=\"sentences\", size=3)\n",
    "show_chunks(chunks)\n",
    "\n",
    "print(\"=== Fixed-length chunking by words (15 words per chunk) ===\")\n",
    "chunks_words = chunk_by_fixed_length(text, unit=\"words\", size=15)\n",
    "show_chunks(chunks_words[:3])  # Show first 3 chunks only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b953d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034660fd",
   "metadata": {},
   "source": [
    "\n",
    "## 2) 슬라이딩 윈도우 청킹 (Sliding Window)\n",
    "\n",
    "**개념**: 일정 길이의 윈도우를 **겹치게** 이동시키며 분할합니다.  \n",
    "**장점**: 인접 청크 간 문맥이 유지되어 **의미 단절 최소화**. 긴 텍스트의 주제 전환 처리에 유리.  \n",
    "**단점**: 중복 임베딩으로 **처리량 증가**.\n",
    "\n",
    "예문은 3문장 윈도우, 1문장씩 이동(step=1)으로 분할합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a1635bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sliding Window Chunking (Word-based) ===\n",
      "Window size: 10 words, Overlap ratio: 0.5 (50% overlap)\n",
      "Notice how adjacent chunks share words for better context!\n",
      "\n",
      "[1] Data science combines statistics and computer science. It helps us find patterns in large datasets. The goal is to extract\n",
      "\n",
      "[2] to extract meaningful insights from data. Machine learning is a key tool in data science. It can predict future outcomes\n",
      "\n",
      "[3] future outcomes based on past data. Popular algorithms include linear regression and decision trees. Data visualization makes insights easier to\n",
      "\n",
      "[4] easier to understand. Charts and graphs help communicate findings. Tools like matplotlib and seaborn are commonly used. Big data refers\n",
      "\n",
      "[5] data refers to datasets that are too large for traditional processing. Distributed computing frameworks like Hadoop help handle big data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "def simple_sent_split(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into sentences using simple rules.\n",
    "    - Split on periods, question marks, exclamation marks\n",
    "    - Split on line breaks\n",
    "    \"\"\"\n",
    "    # First split by line breaks\n",
    "    parts = re.split(r\"\\n+\", text.strip())\n",
    "    sentences = []\n",
    "    \n",
    "    for part in parts:\n",
    "        # Split on punctuation marks\n",
    "        split_sentences = re.split(r\"(?<=[\\.!\\?])\\s+\", part.strip())\n",
    "        # Filter out empty strings\n",
    "        split_sentences = [s for s in split_sentences if s]\n",
    "        sentences.extend(split_sentences)\n",
    "    \n",
    "    # Clean up: remove extra whitespace\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def chunk_by_sliding_window(text: str, window_size: int = 10, overlap_ratio: float = 0.5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Sliding window chunking: Create overlapping chunks by sliding a window across words.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to chunk\n",
    "        window_size: Number of words in each chunk\n",
    "        overlap_ratio: Ratio of overlap (0.0 = no overlap, 0.5 = 50% overlap, 0.8 = 80% overlap)\n",
    "    \n",
    "    Returns:\n",
    "        List of overlapping text chunks\n",
    "    \"\"\"\n",
    "    # Step 1: Split text into words\n",
    "    words = re.findall(r\"\\S+\", text)\n",
    "    \n",
    "    # Step 2: Calculate step size based on overlap ratio\n",
    "    # step = window_size * (1 - overlap_ratio)\n",
    "    step = int(window_size * (1 - overlap_ratio))\n",
    "    step = max(1, step)  # Ensure step is at least 1\n",
    "    \n",
    "    # Step 3: Create sliding windows\n",
    "    chunks = []\n",
    "    for i in range(0, len(words) - window_size + 1, step):\n",
    "        # Get a window of words\n",
    "        window_words = words[i:i+window_size]\n",
    "        # Join them into a chunk\n",
    "        chunk = \" \".join(window_words)\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def show_chunks(chunks):\n",
    "    \"\"\"Display chunks in a numbered format\"\"\"\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"[{i}] {chunk}\\n\")\n",
    "\n",
    "# Example: Let's use sliding window on a text about data science\n",
    "text = \"\"\"\n",
    "Data science combines statistics and computer science. It helps us find patterns in large datasets. The goal is to extract meaningful insights from data.\n",
    "Machine learning is a key tool in data science. It can predict future outcomes based on past data. Popular algorithms include linear regression and decision trees.\n",
    "Data visualization makes insights easier to understand. Charts and graphs help communicate findings. Tools like matplotlib and seaborn are commonly used.\n",
    "Big data refers to datasets that are too large for traditional processing. Distributed computing frameworks like Hadoop help handle big data. Cloud platforms provide scalable storage and processing.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Sliding Window Chunking (Word-based) ===\")\n",
    "print(\"Window size: 10 words, Overlap ratio: 0.5 (50% overlap)\")\n",
    "print(\"Notice how adjacent chunks share words for better context!\\n\")\n",
    "\n",
    "chunks = chunk_by_sliding_window(text, window_size=20, overlap_ratio=0.1)\n",
    "show_chunks(chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338a8444",
   "metadata": {},
   "source": [
    "\n",
    "## 4) 구조 기반 청킹 (Structure-aware)\n",
    "\n",
    "**개념**: 문서의 **형식적 구조**(마크다운 헤더, 코드블록, HTML 태그 등)를 경계로 분할합니다.  \n",
    "**장점**: 구현이 비교적 간단하며 구조 정보에 그대로 의존 가능.  \n",
    "**단점**: 구조 인식이 어려운 문서에는 한계가 있고, 동일한 구조라도 문서마다 의미 차이가 존재할 수 있음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec2e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Structure-based Chunking ===\n",
      "This method splits text based on markdown headers and preserves code blocks.\n",
      "\n",
      "[1] <No Title>\n",
      "\n",
      "\n",
      "[2] <Python Basics>\n",
      "Python is a high-level programming language. It's known for its simple syntax and readability. Python supports multiple programming paradigms.\n",
      "\n",
      "[3] <Variables and Data Types>\n",
      "Variables in Python don't need explicit declaration. You can assign values directly. Common data types include integers, floats, strings, and booleans.\n",
      "\n",
      "```python\n",
      "# Example of variable assignment\n",
      "name = \"Alice\"\n",
      "age = 25\n",
      "is_student = True\n",
      "```\n",
      "\n",
      "[4] <Control Structures>\n",
      "Python uses indentation to define code blocks. This makes the code more readable. Common control structures include if-else statements and loops.\n",
      "\n",
      "```python\n",
      "# Example of if-else statement\n",
      "if age >= 18:\n",
      "    print(\"Adult\")\n",
      "else:\n",
      "    print(\"Minor\")\n",
      "```\n",
      "\n",
      "[5] <Functions>\n",
      "Functions help organize code into reusable blocks. They can take parameters and return values. Python has many built-in functions.\n",
      "\n",
      "```python\n",
      "def greet(name):\n",
      "    return f\"Hello, {name}!\"\n",
      "```\n",
      "\n",
      "[6] <Best Practices>\n",
      "Good Python code follows certain conventions. Use meaningful variable names. Write clear comments. Keep functions small and focused.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "def chunk_by_structure_markdown(text: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Structure-based chunking: Split text based on markdown headers and code blocks.\n",
    "    \n",
    "    Args:\n",
    "        text: Input markdown text to chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of (title, content) tuples. Empty title if no header found.\n",
    "    \"\"\"\n",
    "    lines = text.splitlines()\n",
    "    chunks = []\n",
    "    current_content = []\n",
    "    current_title = \"\"\n",
    "    in_code_block = False\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check if we're entering or exiting a code block\n",
    "        if line.strip().startswith(\"```\"):\n",
    "            in_code_block = not in_code_block\n",
    "            current_content.append(line)\n",
    "            continue\n",
    "        \n",
    "        # Check if this is a header (not inside code block)\n",
    "        if not in_code_block and re.match(r\"^\\s{0,3}#{1,6}\\s\", line):\n",
    "            # Save previous chunk if it has content\n",
    "            if current_content:\n",
    "                content = \"\\n\".join(current_content).strip()\n",
    "                chunks.append((current_title, content))\n",
    "                current_content = []\n",
    "            \n",
    "            # Extract title from header\n",
    "            current_title = re.sub(r\"^\\s{0,3}#{1,6}\\s*\", \"\", line).strip()\n",
    "        else:\n",
    "            # Regular content line\n",
    "            current_content.append(line)\n",
    "    \n",
    "    # Don't forget the last chunk\n",
    "    if current_content:\n",
    "        content = \"\\n\".join(current_content).strip()\n",
    "        chunks.append((current_title, content))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Example: Let's chunk a markdown document about Python programming\n",
    "markdown_text = \"\"\"\n",
    "# Python Basics\n",
    "\n",
    "Python is a high-level programming language. It's known for its simple syntax and readability. Python supports multiple programming paradigms.\n",
    "\n",
    "## Variables and Data Types\n",
    "\n",
    "Variables in Python don't need explicit declaration. You can assign values directly. Common data types include integers, floats, strings, and booleans.\n",
    "\n",
    "```python\n",
    "# Example of variable assignment\n",
    "name = \"Alice\"\n",
    "age = 25\n",
    "is_student = True\n",
    "```\n",
    "\n",
    "## Control Structures\n",
    "\n",
    "Python uses indentation to define code blocks. This makes the code more readable. Common control structures include if-else statements and loops.\n",
    "\n",
    "```python\n",
    "# Example of if-else statement\n",
    "if age >= 18:\n",
    "    print(\"Adult\")\n",
    "else:\n",
    "    print(\"Minor\")\n",
    "```\n",
    "\n",
    "## Functions\n",
    "\n",
    "Functions help organize code into reusable blocks. They can take parameters and return values. Python has many built-in functions.\n",
    "\n",
    "```python\n",
    "def greet(name):\n",
    "    return f\"Hello, {name}!\"\n",
    "```\n",
    "\n",
    "# Best Practices\n",
    "\n",
    "Good Python code follows certain conventions. Use meaningful variable names. Write clear comments. Keep functions small and focused.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Structure-based Chunking ===\")\n",
    "print(\"This method splits text based on markdown headers and preserves code blocks.\\n\")\n",
    "\n",
    "blocks = chunk_by_structure_markdown(markdown_text)\n",
    "\n",
    "for i, (title, content) in enumerate(blocks, 1):\n",
    "    print(f\"[{i}] <{title or 'No Title'}>\")\n",
    "    print(content)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7e9831",
   "metadata": {},
   "source": [
    "\n",
    "## 5) 계층 구조 기반 청킹 (Hierarchical)\n",
    "\n",
    "**개념**: 문서의 논리적 **계층**을 인식해 상위/하위 내용을 함께 관리합니다.  \n",
    "각 청크가 상위 제목(맥락)을 **헤더로 포함**하도록 설계하여, 섹션 기반 검색/요약/인덱싱에 강합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "946d31a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Hierarchical Chunking ===\n",
      "This method preserves document structure by keeping section titles with each chunk.\n",
      "\n",
      "[1] <Introduction>\n",
      "Retrieval-Augmented Generation (RAG) combines search and generation. It enhances language models with external knowledge.\n",
      "\n",
      "[2] <Introduction>\n",
      "The main advantage is improved accuracy and up-to-date information.\n",
      "\n",
      "[3] <Architecture>\n",
      "RAG systems have two main components. The retriever finds relevant documents.\n",
      "\n",
      "[4] <Architecture>\n",
      "The generator creates responses based on retrieved content. This separation allows for better control and optimization.\n",
      "\n",
      "[5] <Retrieval Component>\n",
      "The retriever uses vector similarity search. Documents are converted to embeddings.\n",
      "\n",
      "[6] <Retrieval Component>\n",
      "Queries are also converted to embeddings. Similarity is measured using cosine distance.\n",
      "\n",
      "[7] <Generation Component>\n",
      "The generator is typically a large language model. It takes retrieved documents as context.\n",
      "\n",
      "[8] <Generation Component>\n",
      "The model generates responses based on this context. Fine-tuning can improve performance.\n",
      "\n",
      "[9] <Implementation>\n",
      "Building a RAG system requires several steps. First, prepare and index your documents.\n",
      "\n",
      "[10] <Implementation>\n",
      "Second, implement the retrieval mechanism. Third, integrate with a language model.\n",
      "\n",
      "[11] <Document Processing>\n",
      "Documents need to be cleaned and chunked. Chunking strategies affect retrieval quality.\n",
      "\n",
      "[12] <Document Processing>\n",
      "Smaller chunks provide more precise matches. Larger chunks provide more context.\n",
      "\n",
      "[13] <Vector Database>\n",
      "A vector database stores document embeddings. Popular options include Pinecone and Weaviate.\n",
      "\n",
      "[14] <Vector Database>\n",
      "The database must support similarity search. Performance depends on indexing strategy.\n",
      "\n",
      "[15] <Best Practices>\n",
      "Good RAG systems follow certain principles. Use high-quality source documents.\n",
      "\n",
      "[16] <Best Practices>\n",
      "Implement proper chunking strategies. Monitor and evaluate system performance regularly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "def simple_sent_split(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into sentences using simple rules.\n",
    "    - Split on periods, question marks, exclamation marks\n",
    "    - Split on line breaks\n",
    "    \"\"\"\n",
    "    # First split by line breaks\n",
    "    parts = re.split(r\"\\n+\", text.strip())\n",
    "    sentences = []\n",
    "    \n",
    "    for part in parts:\n",
    "        # Split on punctuation marks\n",
    "        split_sentences = re.split(r\"(?<=[\\.!\\?])\\s+\", part.strip())\n",
    "        # Filter out empty strings\n",
    "        split_sentences = [s for s in split_sentences if s]\n",
    "        sentences.extend(split_sentences)\n",
    "    \n",
    "    # Clean up: remove extra whitespace\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def chunk_by_structure_markdown(text: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Structure-based chunking: Split text based on markdown headers and code blocks.\n",
    "    \n",
    "    Args:\n",
    "        text: Input markdown text to chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of (title, content) tuples. Empty title if no header found.\n",
    "    \"\"\"\n",
    "    lines = text.splitlines()\n",
    "    chunks = []\n",
    "    current_content = []\n",
    "    current_title = \"\"\n",
    "    in_code_block = False\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check if we're entering or exiting a code block\n",
    "        if line.strip().startswith(\"```\"):\n",
    "            in_code_block = not in_code_block\n",
    "            current_content.append(line)\n",
    "            continue\n",
    "        \n",
    "        # Check if this is a header (not inside code block)\n",
    "        if not in_code_block and re.match(r\"^\\s{0,3}#{1,6}\\s\", line):\n",
    "            # Save previous chunk if it has content\n",
    "            if current_content:\n",
    "                content = \"\\n\".join(current_content).strip()\n",
    "                chunks.append((current_title, content))\n",
    "                current_content = []\n",
    "            \n",
    "            # Extract title from header\n",
    "            current_title = re.sub(r\"^\\s{0,3}#{1,6}\\s*\", \"\", line).strip()\n",
    "        else:\n",
    "            # Regular content line\n",
    "            current_content.append(line)\n",
    "    \n",
    "    # Don't forget the last chunk\n",
    "    if current_content:\n",
    "        content = \"\\n\".join(current_content).strip()\n",
    "        chunks.append((current_title, content))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def chunk_hierarchical(text: str, section_depth: int = 2, leaf_sent_limit: int = 3) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Hierarchical chunking: Create chunks that preserve document structure.\n",
    "    \n",
    "    This method:\n",
    "    1. First splits by major sections (headers)\n",
    "    2. Then splits each section into smaller chunks by sentences\n",
    "    3. Each chunk includes the section title for context\n",
    "    \n",
    "    Args:\n",
    "        text: Input markdown text to chunk\n",
    "        section_depth: How deep to go in the hierarchy (not used in this simple version)\n",
    "        leaf_sent_limit: Maximum sentences per leaf chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of (section_title, chunk_content) tuples\n",
    "    \"\"\"\n",
    "    # Step 1: Split by major sections using markdown headers\n",
    "    sections = chunk_by_structure_markdown(text)\n",
    "    \n",
    "    # Step 2: Split each section into smaller chunks\n",
    "    hierarchical_chunks = []\n",
    "    \n",
    "    for section_title, section_content in sections:\n",
    "        # Split section content into sentences\n",
    "        sentences = simple_sent_split(section_content)\n",
    "        \n",
    "        # Create chunks of sentences within this section\n",
    "        for i in range(0, len(sentences), leaf_sent_limit):\n",
    "            # Get a chunk of sentences\n",
    "            chunk_sentences = sentences[i:i+leaf_sent_limit]\n",
    "            chunk_content = \" \".join(chunk_sentences)\n",
    "            \n",
    "            # Store with section title for context\n",
    "            hierarchical_chunks.append((section_title, chunk_content))\n",
    "    \n",
    "    return hierarchical_chunks\n",
    "\n",
    "# Example: Let's create hierarchical chunks from a technical document\n",
    "document = \"\"\"\n",
    "# Introduction\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) combines search and generation. It enhances language models with external knowledge. The main advantage is improved accuracy and up-to-date information.\n",
    "\n",
    "# Architecture\n",
    "\n",
    "RAG systems have two main components. The retriever finds relevant documents. The generator creates responses based on retrieved content. This separation allows for better control and optimization.\n",
    "\n",
    "## Retrieval Component\n",
    "\n",
    "The retriever uses vector similarity search. Documents are converted to embeddings. Queries are also converted to embeddings. Similarity is measured using cosine distance.\n",
    "\n",
    "## Generation Component\n",
    "\n",
    "The generator is typically a large language model. It takes retrieved documents as context. The model generates responses based on this context. Fine-tuning can improve performance.\n",
    "\n",
    "# Implementation\n",
    "\n",
    "Building a RAG system requires several steps. First, prepare and index your documents. Second, implement the retrieval mechanism. Third, integrate with a language model.\n",
    "\n",
    "## Document Processing\n",
    "\n",
    "Documents need to be cleaned and chunked. Chunking strategies affect retrieval quality. Smaller chunks provide more precise matches. Larger chunks provide more context.\n",
    "\n",
    "## Vector Database\n",
    "\n",
    "A vector database stores document embeddings. Popular options include Pinecone and Weaviate. The database must support similarity search. Performance depends on indexing strategy.\n",
    "\n",
    "# Best Practices\n",
    "\n",
    "Good RAG systems follow certain principles. Use high-quality source documents. Implement proper chunking strategies. Monitor and evaluate system performance regularly.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Hierarchical Chunking ===\")\n",
    "print(\"This method preserves document structure by keeping section titles with each chunk.\\n\")\n",
    "\n",
    "hierarchical_chunks = chunk_hierarchical(document, section_depth=2, leaf_sent_limit=2)\n",
    "\n",
    "for i, (section_title, chunk_content) in enumerate(hierarchical_chunks, 1):\n",
    "    print(f\"[{i}] <{section_title}>\")\n",
    "    print(chunk_content)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
