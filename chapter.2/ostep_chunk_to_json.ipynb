{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3332cb09",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 2: OSTEP 전처리 및 청크 JSON 저장\n",
    "\n",
    "이 노트북은 OSTEP 교재 PDF를 전처리하고 토큰 기반 청킹 후 JSON으로 저장하는 전체 과정을 단계별로 실습합니다.\n",
    "\n",
    "## 📚 학습 목표\n",
    "- PDF → 텍스트 추출 파이프라인 구성 및 품질 관리 포인트 이해\n",
    "- 목차(챕터/파트/서브섹션) 파싱과 페이지 범위 계산 방법 습득\n",
    "- 문장 경계 유지형 토큰 기반 청킹과 오버랩 설계 이해\n",
    "\n",
    "## 📋 실습 구성\n",
    "- 1️⃣ 환경 설정: 패키지 설치, 경로/상수 정의, 데이터 위치 확인\n",
    "- 2️⃣ 임포트/상수: 정규식 패턴, 토큰/오버랩, 분리 규칙 등 설정\n",
    "- 3️⃣ PDF 로드/기본 함수: 페이지 안전 추출 유틸리티 준비\n",
    "- 4️⃣ 목차 파싱: 챕터/파트/서브섹션 구조화\n",
    "- 5️⃣ 범위 계산/텍스트 추출: 챕터별 범위 산출 및 정제\n",
    "- 6️⃣ 청크 생성/저장: 문장 경계 유지형 토큰 청킹 → JSON 저장\n",
    "- 7️⃣ 결과 요약: 범위/문자수/서브섹션 통계 출력\n",
    "\n",
    "> ⚠️ 실습 셀 실행 전, 환경 설정 셀(1️⃣)을 먼저 실행하고 OSTEP PDF 경로를 확인하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc101372",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 1️⃣ Google Colab 환경 설정\n",
    "\n",
    "이 노트북은 **Google Colab에서 GPU를 사용**하여 실행하도록 설계되었습니다.\n",
    "\n",
    "### 📌 실행 전 준비사항\n",
    "1. **런타임 유형 설정**: 메뉴에서 `런타임` → `런타임 유형 변경` → `GPU` 선택\n",
    "2. **첫 번째 코드 셀 실행**: Google Drive 마운트 및 필수 패키지 자동 설치\n",
    "3. **OSTEP PDF 업로드**: 최초 1회만 `/content/drive/MyDrive/ostep_rag/data/documents/ostep.pdf` 위치에 업로드\n",
    "\n",
    "> ⚠️ **중요**: 아래 코드 셀을 가장 먼저 실행하여 환경을 설정하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "colab_setup",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ========================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Google Colab 환경 설정\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ========================================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Google Drive 마운트\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Google Colab 환경 설정\n",
    "# ========================================\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Google Drive 마운트\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 필요 패키지 설치\n",
    "!pip -q install PyPDF2 pdfplumber pymupdf tiktoken\n",
    "\n",
    "# 경로 설정 (Colab 전용)\n",
    "BASE_DIR = \"/content/drive/MyDrive/ostep_rag\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "DOC_ID = \"ostep\"\n",
    "OUTPUT_DIR = os.path.join(DATA_DIR, \"chunk\")\n",
    "PDF_PATH = os.path.join(DATA_DIR, \"documents\", \"ostep.pdf\")\n",
    "\n",
    "# 디렉토리 생성\n",
    "os.makedirs(os.path.join(DATA_DIR, \"documents\"), exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# OSTEP PDF 업로드 확인\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    print(f\"⚠️ 구글 드라이브에 OSTEP PDF를 업로드하세요:\")\n",
    "    print(f\"   {PDF_PATH}\")\n",
    "    print(f\"\\n📁 좌측 파일 탭 → drive → MyDrive → ostep_rag → data → documents 폴더에 ostep.pdf 업로드\")\n",
    "else:\n",
    "    print(f\"✅ OSTEP PDF 파일 확인됨: {PDF_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14830a1",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 2️⃣ 임포트 및 설정 상수\n",
    "\n",
    "이 셀에서는 필요한 라이브러리를 임포트하고 전역 설정 상수를 정의합니다.\n",
    "\n",
    "**주요 내용:**\n",
    "- PyPDF2를 사용하여 PDF 파일 처리\n",
    "- 정규식 패턴을 사용하여 목차에서 챕터, 파트, 서브섹션 파싱\n",
    "- 토큰 기반 청킹 설정(최대 토큰, 오버랩 토큰)\n",
    "- 출력 디렉토리 및 문서 ID 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba277ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 설정 상수\n",
    "TOC_START_PAGE = 15\n",
    "TOC_END_PAGE = 25\n",
    "PAGE_OFFSET = 36\n",
    "CHUNK_MAX_TOKENS = 400\n",
    "CHUNK_OVERLAP_TOKENS = 80\n",
    "SENTENCE_SPLIT_REGEX = r'(?<=[.!?])\\s+(?=[A-Z0-9])'\n",
    "\n",
    "# 정규식 패턴\n",
    "MAIN_CHAPTER_PATTERNS = [\n",
    "    r'^(\\d+)\\s+(.+?)\\s+\\.{3,}\\s*(\\d+)$',\n",
    "    r'^(\\d+)\\s+(.+?)\\s+(\\d+)$'\n",
    "]\n",
    "\n",
    "PART_PATTERNS = [\n",
    "    r'^([IVX]+)\\s+(.+?)\\s+\\.{3,}\\s*(\\d+)$',\n",
    "    r'^([IVX]+)\\s+(.+?)\\s+(\\d+)$'\n",
    "]\n",
    "\n",
    "SUBSECTION_PATTERNS = [\n",
    "    r'^(\\d+\\.\\d+)\\s+(.+?)\\s+\\.{3,}\\s*(\\d+)$',\n",
    "    r'^(\\d+\\.\\d+)\\s+(.+?)\\s+(\\d+)$'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b647b",
   "metadata": {},
   "source": [
    "---\n",
    "## 3️⃣ PDF 로드 및 기본 함수\n",
    "\n",
    "이 셀에서는 PDF 파일을 로드하고 기본적인 텍스트 추출 함수를 정의합니다.\n",
    "\n",
    "**주요 함수:**\n",
    "- `load_pdf()`: PDF 파일을 로드하고 페이지 수를 확인\n",
    "- `extract_pdf_text()`: 지정된 페이지 범위에서 텍스트를 추출\n",
    "\n",
    "**실행 결과:**\n",
    "- PDF 파일이 성공적으로 로드되고 전체 페이지 수가 출력됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053adb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 로드 완료: 643 페이지\n"
     ]
    }
   ],
   "source": [
    "def load_pdf(pdf_path: str):\n",
    "    \"\"\"PDF 파일 로드\"\"\"\n",
    "    pdf_path = Path(pdf_path)\n",
    "    if not pdf_path.exists():\n",
    "        raise FileNotFoundError(f\"PDF 파일을 찾을 수 없습니다: {pdf_path}\")\n",
    "    \n",
    "    reader = PdfReader(pdf_path)\n",
    "    print(f\"PDF 로드 완료: {len(reader.pages)} 페이지\")\n",
    "    return reader\n",
    "\n",
    "def extract_pdf_text(reader, start_page: int, end_page: int):\n",
    "    \"\"\"PDF 페이지 범위에서 텍스트 추출\"\"\"\n",
    "    total_pages = len(reader.pages)\n",
    "    if start_page < 1 or end_page > total_pages:\n",
    "        start_page = max(1, start_page)\n",
    "        end_page = min(total_pages, end_page)\n",
    "    \n",
    "    text = \"\"\n",
    "    for page_num in range(start_page - 1, end_page):\n",
    "        page = reader.pages[page_num]\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# PDF 로드 실행\n",
    "pdf_path = PDF_PATH\n",
    "reader = load_pdf(PDF_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2bcc01",
   "metadata": {},
   "source": [
    "---\n",
    "## 4️⃣ 목차 파싱\n",
    "\n",
    "이 셀에서는 PDF 목차를 파싱하여 챕터, 파트, 서브섹션 정보를 추출합니다.\n",
    "\n",
    "**주요 함수:**\n",
    "- `create_toc_entry()`: 목차 항목을 딕셔너리로 생성\n",
    "- `parse_chapter_line()`, `parse_part_line()`, `parse_subsection_line()`: 각 유형별 라인 파싱\n",
    "- `parse_toc()`: 목차 전체를 파싱하여 3가지 유형으로 분류\n",
    "\n",
    "**실행 결과:**\n",
    "- 챕터, 파트, 서브섹션의 개수가 출력됩니다.\n",
    "- 정규식 패턴으로 목차의 구조를 인식하여 계층 구조를 파악합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bdba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목차 파싱 중 (페이지 15-25)...\n",
      "목차 파싱 완료: 50개 챕터, 3개 파트, 297개 서브섹션\n"
     ]
    }
   ],
   "source": [
    "def create_toc_entry(entry_type: str, number, title: str, toc_page: int):\n",
    "    \"\"\"TOC 항목 생성 (딕셔너리 반환)\"\"\"\n",
    "    actual_page = toc_page + PAGE_OFFSET\n",
    "    \n",
    "    if entry_type == 'part':\n",
    "        full_title = f\"{number} {title}\"\n",
    "        entry_id = f\"part_{number}\"\n",
    "    elif entry_type == 'subsection':\n",
    "        full_title = f\"{number} {title}\"\n",
    "        entry_id = f\"subsec_{number}\"\n",
    "    else:  # chapter\n",
    "        full_title = f\"{number} {title}\"\n",
    "        entry_id = f\"ch_{number}\"\n",
    "    \n",
    "    return {\n",
    "        'entry_type': entry_type,\n",
    "        'number': number,\n",
    "        'title': title,\n",
    "        'toc_page': toc_page,\n",
    "        'actual_page': actual_page,\n",
    "        'full_title': full_title,\n",
    "        'id': entry_id\n",
    "    }\n",
    "\n",
    "def clean_toc_title(title: str):\n",
    "    \"\"\"목차 제목 정제\"\"\"\n",
    "    title = re.sub(r'\\s*[\\.\\s]{4,}.*$', '', title)\n",
    "    title = re.sub(r'\\s*\\.{3,}.*$', '', title)\n",
    "    title = re.sub(r'\\s*\\.+\\s*$', '', title)\n",
    "    title = re.sub(r'\\s+', ' ', title)\n",
    "    return title.strip()\n",
    "\n",
    "def is_valid_title(title: str):\n",
    "    \"\"\"제목 유효성 검사\"\"\"\n",
    "    return (bool(title) and \n",
    "            len(title) > 3 and \n",
    "            not title.strip().isdigit() and \n",
    "            title[0].isupper())\n",
    "\n",
    "def parse_chapter_line(line: str):\n",
    "    \"\"\"챕터 라인 파싱\"\"\"\n",
    "    for pattern in MAIN_CHAPTER_PATTERNS:\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            chapter_num = int(match.group(1))\n",
    "            title = clean_toc_title(match.group(2).strip())\n",
    "            page_num = int(match.group(3))\n",
    "            \n",
    "            if is_valid_title(title):\n",
    "                return create_toc_entry('chapter', chapter_num, title, page_num)\n",
    "    return None\n",
    "\n",
    "def parse_part_line(line: str):\n",
    "    \"\"\"파트 라인 파싱\"\"\"\n",
    "    for pattern in PART_PATTERNS:\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            part_num = match.group(1)\n",
    "            title = clean_toc_title(match.group(2).strip())\n",
    "            page_num = int(match.group(3))\n",
    "            \n",
    "            if is_valid_title(title):\n",
    "                return create_toc_entry('part', part_num, title, page_num)\n",
    "    return None\n",
    "\n",
    "def parse_subsection_line(line: str):\n",
    "    \"\"\"서브섹션 라인 파싱 (예: 2.1, 4.2 등)\"\"\"\n",
    "    for pattern in SUBSECTION_PATTERNS:\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            subsection_num = match.group(1)\n",
    "            title = clean_toc_title(match.group(2).strip())\n",
    "            page_num = int(match.group(3))\n",
    "            \n",
    "            if is_valid_title(title):\n",
    "                return create_toc_entry('subsection', subsection_num, title, page_num)\n",
    "    return None\n",
    "\n",
    "def parse_toc(reader):\n",
    "    \"\"\"목차 파싱 (챕터 + 파트 + 서브섹션)\"\"\"\n",
    "    print(f\"목차 파싱 중 (페이지 {TOC_START_PAGE}-{TOC_END_PAGE})...\")\n",
    "    \n",
    "    toc_text = extract_pdf_text(reader, TOC_START_PAGE, TOC_END_PAGE)\n",
    "    if not toc_text:\n",
    "        print(\"목차 텍스트 추출 실패\")\n",
    "        return [], [], []\n",
    "    \n",
    "    chapters = []\n",
    "    parts = []\n",
    "    subsections = []\n",
    "    \n",
    "    for line in toc_text.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # 파트 파싱 우선 시도\n",
    "        part_entry = parse_part_line(line)\n",
    "        if part_entry:\n",
    "            parts.append(part_entry)\n",
    "            continue\n",
    "        \n",
    "        # 서브섹션 파싱 시도\n",
    "        subsection_entry = parse_subsection_line(line)\n",
    "        if subsection_entry:\n",
    "            subsections.append(subsection_entry)\n",
    "            continue\n",
    "        \n",
    "        # 챕터 파싱\n",
    "        chapter_entry = parse_chapter_line(line)\n",
    "        if chapter_entry:\n",
    "            chapters.append(chapter_entry)\n",
    "    \n",
    "    # 페이지 순서로 정렬\n",
    "    chapters.sort(key=lambda x: x['toc_page'])\n",
    "    parts.sort(key=lambda x: x['toc_page'])\n",
    "    subsections.sort(key=lambda x: x['toc_page'])\n",
    "    \n",
    "    print(f\"목차 파싱 완료: {len(chapters)}개 챕터, {len(parts)}개 파트, {len(subsections)}개 서브섹션\")\n",
    "    return chapters, parts, subsections\n",
    "\n",
    "# 목차 파싱 실행\n",
    "chapters, parts, subsections = parse_toc(reader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee5e56",
   "metadata": {},
   "source": [
    "---\n",
    "## 5️⃣ 챕터 범위 계산\n",
    "\n",
    "이 셀에서는 각 챕터가 차지하는 페이지 범위를 계산합니다.\n",
    "\n",
    "**주요 함수:**\n",
    "- `find_part_for_chapter()`: 챕터가 속한 파트를 찾기\n",
    "- `calculate_chapter_ranges()`: 챕터별 시작/종료 페이지를 계산\n",
    "\n",
    "**실행 결과:**\n",
    "- 각 챕터의 페이지 범위가 계산됩니다.\n",
    "- 다음 챕터 시작 전까지가 현재 챕터의 마지막 페이지입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챕터별 페이지 범위 계산 중...\n",
      "챕터 범위 계산 완료: 50개 챕터\n"
     ]
    }
   ],
   "source": [
    "def find_part_for_chapter(chapter, parts):\n",
    "    \"\"\"챕터가 속한 파트 찾기\"\"\"\n",
    "    current_part = None\n",
    "    for part in parts:\n",
    "        if part['actual_page'] <= chapter['actual_page']:\n",
    "            current_part = part\n",
    "        else:\n",
    "            break\n",
    "    return current_part\n",
    "\n",
    "def calculate_chapter_ranges(reader, chapters, parts):\n",
    "    \"\"\"챕터별 페이지 범위 계산\"\"\"\n",
    "    print(\"챕터별 페이지 범위 계산 중...\")\n",
    "    \n",
    "    if not chapters:\n",
    "        print(\"메인 챕터를 찾을 수 없습니다.\")\n",
    "        return []\n",
    "    \n",
    "    chapter_ranges = []\n",
    "    total_pages = len(reader.pages)\n",
    "    \n",
    "    for i, chapter in enumerate(chapters):\n",
    "        start_page = chapter['actual_page']\n",
    "        \n",
    "        # 다음 챕터가 있으면 그 전 페이지까지, 없으면 PDF 끝까지\n",
    "        if i + 1 < len(chapters):\n",
    "            end_page = chapters[i + 1]['actual_page'] - 1\n",
    "        else:\n",
    "            end_page = total_pages\n",
    "        \n",
    "        # 해당 챕터가 속한 파트 찾기\n",
    "        part_info = find_part_for_chapter(chapter, parts)\n",
    "        \n",
    "        # 페이지 범위 유효성 검사\n",
    "        if start_page <= end_page:\n",
    "            chapter_range = {\n",
    "                'toc_entry': chapter,\n",
    "                'part_info': part_info,\n",
    "                'start_page': start_page,\n",
    "                'end_page': end_page,\n",
    "                'page_count': end_page - start_page + 1\n",
    "            }\n",
    "            chapter_ranges.append(chapter_range)\n",
    "    \n",
    "    print(f\"챕터 범위 계산 완료: {len(chapter_ranges)}개 챕터\")\n",
    "    return chapter_ranges\n",
    "\n",
    "# 챕터 범위 계산 실행\n",
    "chapter_ranges = calculate_chapter_ranges(reader, chapters, parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f526e",
   "metadata": {},
   "source": [
    "---\n",
    "## 6️⃣ 텍스트 추출 및 서브섹션 분할\n",
    "\n",
    "이 셀에서는 각 챕터의 텍스트를 추출하고 서브섹션으로 분할합니다.\n",
    "\n",
    "**주요 함수:**\n",
    "- `clean_text()`: PDF 헤더/푸터, 페이지 번호 제거 및 공백 정리\n",
    "- `find_chapter_subsections()`: 챕터에 속한 서브섹션들 찾기\n",
    "- `split_text_by_subsections()`: 텍스트를 서브섹션별로 분할\n",
    "- `extract_texts()`: 모든 챕터에서 텍스트 추출 및 서브섹션 분할\n",
    "\n",
    "**실행 결과:**\n",
    "- 각 챕터의 텍스트가 추출되고 서브섹션별로 분할됩니다.\n",
    "- 헤더/푸터 등 불필요한 요소가 제거된 깨끗한 텍스트를 얻습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b0db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챕터별 텍스트 추출 및 서브섹션 분할 중...\n",
      "챕터별 텍스트 추출 및 서브섹션 분할 완료: 50개 챕터\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text: str):\n",
    "    \"\"\"텍스트 정제 및 헤더/푸터 제거\"\"\"\n",
    "    # PDF 헤더/푸터 제거\n",
    "    header_pattern = r'c/circle\\s*copyrt\\s*\\d+,?\\s*A\\s+RPACI\\s*-?\\s*D\\s*USSEAU\\s*THREE\\s+EASY\\s+PIECES'\n",
    "    text = re.sub(header_pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    footer_pattern = r'OPERATING\\s+SYSTEMS\\s+\\[VERSION\\s+[\\d.]+\\]\\s+WWW\\s*\\.\\s*OSTEP\\s*\\.\\s*ORG.*$'\n",
    "    text = re.sub(footer_pattern, '', text, flags=re.IGNORECASE | re.MULTILINE)\n",
    "    \n",
    "    # 페이지 번호 패턴 제거\n",
    "    text = re.sub(r'^\\s*\\d+\\s*$', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # 공백 정리\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def find_chapter_subsections(chapter, subsections):\n",
    "    \"\"\"챕터에 속한 서브섹션들 찾기\"\"\"\n",
    "    chapter_num = str(chapter['number'])\n",
    "    chapter_subsections = []\n",
    "    \n",
    "    for subsection in subsections:\n",
    "        # 서브섹션 번호가 해당 챕터로 시작하는지 확인 (예: 2.1, 2.2는 챕터 2에 속함)\n",
    "        subsection_num = str(subsection['number'])\n",
    "        if subsection_num.startswith(f\"{chapter_num}.\"):\n",
    "            chapter_subsections.append(subsection)\n",
    "    \n",
    "    # 번호 순으로 정렬\n",
    "    chapter_subsections.sort(key=lambda x: float(x['number']))\n",
    "    return chapter_subsections\n",
    "\n",
    "def build_flexible_title_pattern(title: str):\n",
    "    \"\"\"제목을 안전한 정규식으로 변환\"\"\"\n",
    "    parts = []\n",
    "    for ch in title:\n",
    "        if ch.isspace():\n",
    "            parts.append(r\"\\s+\")\n",
    "        elif ch == '(':\n",
    "            parts.append(r\"\\s*\\(\\s*\")\n",
    "        elif ch == ')':\n",
    "            parts.append(r\"\\s*\\)\\s*\")\n",
    "        else:\n",
    "            parts.append(re.escape(ch))\n",
    "    return ''.join(parts)\n",
    "\n",
    "def split_text_by_subsections(chapter_text: str, chapter, chapter_subsections):\n",
    "    \"\"\"챕터 텍스트를 서브섹션별로 분할\"\"\"\n",
    "    if not chapter_subsections:\n",
    "        return []\n",
    "    \n",
    "    subsection_data_list = []\n",
    "    \n",
    "    split_points = []\n",
    "    \n",
    "    for subsection in chapter_subsections:\n",
    "        section_title = f\"{subsection['number']} {subsection['title']}\"\n",
    "        \n",
    "        patterns_to_try = [\n",
    "            re.escape(section_title),\n",
    "            f\"{re.escape(str(subsection['number']))}\\\\s+{build_flexible_title_pattern(subsection['title'])}\"\n",
    "        ]\n",
    "\n",
    "        # \"The\" 시작하는 제목의 특수 처리\n",
    "        lower_title = subsection['title'].lower()\n",
    "        if lower_title.startswith(\"the \"):\n",
    "            after_the = subsection['title'][4:]\n",
    "            patterns_to_try.append(\n",
    "                f\"{re.escape(str(subsection['number']))}\\\\s+the\\\\s*{build_flexible_title_pattern(after_the)}\"\n",
    "            )\n",
    "        elif lower_title.startswith(\"the\"):\n",
    "            after_the = subsection['title'][3:]\n",
    "            patterns_to_try.append(\n",
    "                f\"{re.escape(str(subsection['number']))}\\\\s+the\\\\s*{build_flexible_title_pattern(after_the)}\"\n",
    "            )\n",
    "        \n",
    "        found = False\n",
    "        for pattern in patterns_to_try:\n",
    "            matches = list(re.finditer(pattern, chapter_text, re.IGNORECASE | re.MULTILINE))\n",
    "            if matches:\n",
    "                # 첫 번째 매치 사용\n",
    "                match = matches[0]\n",
    "                split_points.append({\n",
    "                    'subsection': subsection,\n",
    "                    'start_pos': match.start(),\n",
    "                    'end_pos': match.end(),\n",
    "                    'title_match': match.group().strip()\n",
    "                })\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            print(f\"  서브섹션 '{subsection['number']} {subsection['title']}' 제목을 텍스트에서 찾을 수 없습니다.\")\n",
    "    \n",
    "    # 위치별로 정렬\n",
    "    split_points.sort(key=lambda x: x['start_pos'])\n",
    "    \n",
    "    # 텍스트 분할\n",
    "    for i, split_point in enumerate(split_points):\n",
    "        start_pos = split_point['start_pos']\n",
    "        \n",
    "        # 다음 서브섹션의 시작 위치 또는 텍스트 끝\n",
    "        if i + 1 < len(split_points):\n",
    "            end_pos = split_points[i + 1]['start_pos']\n",
    "        else:\n",
    "            end_pos = len(chapter_text)\n",
    "        \n",
    "        # 서브섹션 텍스트 추출\n",
    "        subsection_text = chapter_text[start_pos:end_pos].strip()\n",
    "        \n",
    "        if subsection_text:\n",
    "            subsection_data = {\n",
    "                'toc_entry': split_point['subsection'],\n",
    "                'parent_chapter': chapter,\n",
    "                'text': clean_text(subsection_text)\n",
    "            }\n",
    "            subsection_data_list.append(subsection_data)\n",
    "    \n",
    "    return subsection_data_list\n",
    "\n",
    "def extract_texts(reader, chapter_ranges, subsections):\n",
    "    \"\"\"챕터별 텍스트 추출 및 서브섹션 분할\"\"\"\n",
    "    print(f\"챕터별 텍스트 추출 및 서브섹션 분할 중...\")\n",
    "    for chapter_range in chapter_ranges:\n",
    "        chapter = chapter_range['toc_entry']\n",
    "        \n",
    "        # 텍스트 추출\n",
    "        text = extract_pdf_text(reader, chapter_range['start_page'], chapter_range['end_page'])\n",
    "        chapter_range['text'] = clean_text(text)\n",
    "        \n",
    "        # 해당 챕터의 서브섹션들 찾기\n",
    "        chapter_subsections = find_chapter_subsections(chapter, subsections)\n",
    "        \n",
    "        if chapter_subsections:\n",
    "            # 서브섹션별로 텍스트 분할\n",
    "            subsection_data_list = split_text_by_subsections(chapter_range['text'], chapter, chapter_subsections)\n",
    "            chapter_range['subsections'] = subsection_data_list\n",
    "        else:\n",
    "            chapter_range['subsections'] = []\n",
    "    \n",
    "    print(f\"챕터별 텍스트 추출 및 서브섹션 분할 완료: {len(chapter_ranges)}개 챕터\")\n",
    "    return chapter_ranges\n",
    "\n",
    "# 텍스트 추출 및 서브섹션 분할 실행\n",
    "chapter_ranges = extract_texts(reader, chapter_ranges, subsections)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9b194f",
   "metadata": {},
   "source": [
    "---\n",
    "## 7️⃣ 청크 생성 및 JSON 저장\n",
    "\n",
    "이 셀에서는 텍스트를 토큰 기반으로 청킹하고 JSON 파일로 저장합니다.\n",
    "\n",
    "**주요 함수:**\n",
    "- `estimate_tokens_length()`: tiktoken 또는 근사치로 토큰 수 추정\n",
    "- `split_text_into_sentences()`: 정규식으로 문장 분리\n",
    "- `chunk_sentences_hybrid()`: 문장 경계를 유지하며 토큰 제한으로 청킹\n",
    "- `build_all_chunk_records()`: 모든 청크를 레코드로 생성\n",
    "- `write_json()`: JSON 파일로 저장\n",
    "\n",
    "**실행 결과:**\n",
    "- 문장 경계를 유지하면서 토큰 제한(400토큰, 20% 오버랩)에 맞춰 청킹됩니다.\n",
    "- JSON 파일로 저장되어 RAG 시스템에서 사용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b6d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5단계: 청크 생성 및 저장(JSON)\n",
      "----------------------------------------\n",
      "청크 저장 완료: ../data/chunk/ostep_tok400_ov20.json (991 chunks)\n"
     ]
    }
   ],
   "source": [
    "def ensure_output_dir(output_dir: str):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def build_output_path(output_dir: str, max_tokens: int, overlap_tokens: int):\n",
    "    overlap_pct = int(round((overlap_tokens / max_tokens) * 100)) if max_tokens > 0 else 0\n",
    "    filename = f\"{DOC_ID}_tok{max_tokens}_ov{overlap_pct}.json\"\n",
    "    return str(Path(output_dir) / filename)\n",
    "\n",
    "def try_import_tiktoken():\n",
    "    try:\n",
    "        import tiktoken\n",
    "        return tiktoken\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def estimate_tokens_length(text: str):\n",
    "    \"\"\"토큰 길이 추정 (tiktoken 우선, 없으면 근사치)\"\"\"\n",
    "    tiktoken = try_import_tiktoken()\n",
    "    if tiktoken is not None:\n",
    "        try:\n",
    "            enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        except Exception:\n",
    "            enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        return len(enc.encode(text))\n",
    "    return int(len(text.split()) * 1.3)\n",
    "\n",
    "def split_text_into_sentences(text: str):\n",
    "    \"\"\"정규식 기반 문장 분리\"\"\"\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    sentences = re.split(SENTENCE_SPLIT_REGEX, text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    return sentences\n",
    "\n",
    "def chunk_sentences_hybrid(sentences, max_tokens: int, overlap_tokens: int):\n",
    "    \"\"\"문장 경계를 유지하며 토큰 상한으로 청킹\"\"\"\n",
    "    chunks = []\n",
    "    if not sentences:\n",
    "        return chunks\n",
    "\n",
    "    current = []\n",
    "    current_tokens = 0\n",
    "    for sent in sentences:\n",
    "        sent_tokens = estimate_tokens_length(sent)\n",
    "        \n",
    "        if sent_tokens > max_tokens:\n",
    "            if current:\n",
    "                chunks.append(\" \".join(current).strip())\n",
    "                current = []\n",
    "                current_tokens = 0\n",
    "            chunks.append(sent.strip())\n",
    "            continue\n",
    "\n",
    "        if current_tokens + sent_tokens <= max_tokens:\n",
    "            current.append(sent)\n",
    "            current_tokens += sent_tokens\n",
    "        else:\n",
    "            if current:\n",
    "                chunks.append(\" \".join(current).strip())\n",
    "            \n",
    "            if overlap_tokens > 0:\n",
    "                overlap_bucket = []\n",
    "                overlap_count = 0\n",
    "                for prev_sent in reversed(current):\n",
    "                    t = estimate_tokens_length(prev_sent)\n",
    "                    if overlap_count + t > overlap_tokens:\n",
    "                        break\n",
    "                    overlap_bucket.append(prev_sent)\n",
    "                    overlap_count += t\n",
    "                overlap_bucket.reverse()\n",
    "                current = overlap_bucket + [sent]\n",
    "                current_tokens = sum(estimate_tokens_length(s) for s in current)\n",
    "            else:\n",
    "                current = [sent]\n",
    "                current_tokens = sent_tokens\n",
    "\n",
    "    if current:\n",
    "        chunks.append(\" \".join(current).strip())\n",
    "    return chunks\n",
    "\n",
    "def make_chunk_id(chapter_id: str, subsec_id, chunk_index: int):\n",
    "    base = f\"{chapter_id}\"\n",
    "    if subsec_id:\n",
    "        base += f\"__{subsec_id}\"\n",
    "    return f\"{base}__{chunk_index:04d}\"\n",
    "\n",
    "def find_part_for_page(page: int, part_lookup_by_page):\n",
    "\tcurrent = None\n",
    "\tfor start_page, part in part_lookup_by_page:\n",
    "\t\tif start_page <= page:\n",
    "\t\t\tcurrent = part\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\treturn current\n",
    "\n",
    "def build_all_chunk_records(pdf_path: str, parts, chapter_ranges, max_tokens: int, overlap_tokens: int):\n",
    "    part_lookup_by_page = []\n",
    "    for p in parts:\n",
    "        part_lookup_by_page.append((p['actual_page'], p))\n",
    "    part_lookup_by_page.sort(key=lambda x: x[0])\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for cr in chapter_ranges:\n",
    "        chapter = cr['toc_entry']\n",
    "        chapter_id = chapter['id']\n",
    "        chapter_title = chapter['title']\n",
    "        part_info = cr.get('part_info')\n",
    "        if part_info is None:\n",
    "            part_info = find_part_for_page(cr['start_page'], part_lookup_by_page)\n",
    "\n",
    "        # 서브섹션이 있으면 서브섹션 기준, 없으면 챕터 전체 텍스트 기준으로 청킹\n",
    "        if cr.get('subsections'):\n",
    "            for sub in cr['subsections']:\n",
    "                subsec = sub\n",
    "                sentences = split_text_into_sentences(subsec['text'])\n",
    "                chunks = chunk_sentences_hybrid(sentences, max_tokens, overlap_tokens)\n",
    "                for idx, chunk_text in enumerate(chunks):\n",
    "                    records.append({\n",
    "                        'chunk_id': make_chunk_id(chapter_id, subsec['toc_entry']['id'], idx),\n",
    "                        'chapter_id': chapter_id,\n",
    "                        'chapter_title': chapter_title,\n",
    "                        'subsection_id': subsec['toc_entry']['id'],\n",
    "                        'subsection_title': f\"{subsec['toc_entry']['number']} {subsec['toc_entry']['title']}\",\n",
    "                        'text': chunk_text,\n",
    "                    })\n",
    "        else:\n",
    "            sentences = split_text_into_sentences(cr['text'])\n",
    "            chunks = chunk_sentences_hybrid(sentences, max_tokens, overlap_tokens)\n",
    "            for idx, chunk_text in enumerate(chunks):\n",
    "                records.append({\n",
    "                    'chunk_id': make_chunk_id(chapter_id, None, idx),\n",
    "                    'chapter_id': chapter_id,\n",
    "                    'chapter_title': chapter_title,\n",
    "                    'subsection_id': None,\n",
    "                    'subsection_title': None,\n",
    "                    'text': chunk_text,\n",
    "                })\n",
    "\n",
    "    return records\n",
    "\n",
    "def write_json(path: str, records):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 청크 생성 및 저장\n",
    "print(\"\\n5단계: 청크 생성 및 저장(JSON)\")\n",
    "print(\"-\" * 40)\n",
    "ensure_output_dir(OUTPUT_DIR)\n",
    "output_path = build_output_path(OUTPUT_DIR, CHUNK_MAX_TOKENS, CHUNK_OVERLAP_TOKENS)\n",
    "all_chunk_records = build_all_chunk_records(\n",
    "\tpdf_path=pdf_path,\n",
    "\tparts=parts,\n",
    "\tchapter_ranges=chapter_ranges,\n",
    "\tmax_tokens=CHUNK_MAX_TOKENS,\n",
    "\toverlap_tokens=CHUNK_OVERLAP_TOKENS,\n",
    ")\n",
    "write_json(output_path, all_chunk_records)\n",
    "print(f\"청크 저장 완료: {output_path} ({len(all_chunk_records)} chunks)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9d4bf",
   "metadata": {},
   "source": [
    "---\n",
    "## 8️⃣ 결과 요약 출력\n",
    "\n",
    "이 셀에서는 전처리된 데이터의 요약 정보를 출력합니다.\n",
    "\n",
    "**주요 내용:**\n",
    "- 챕터별 페이지 범위, 문자 수, 서브섹션 개수\n",
    "- 서브섹션별 문자 수\n",
    "\n",
    "**실행 결과:**\n",
    "- 각 챕터와 서브섹션의 상세 정보가 출력됩니다.\n",
    "- 전처리 품질을 확인하고 개선점을 파악할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104af0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chapter information:\n",
      "  • 1 A Dialogue on the Book (Unclassified): 37-38 (2p, 3,519 chars, 0 subsections)\n",
      "  • 2 Introduction to Operating Systems (Unclassified): 39-58 (20p, 44,104 chars, 7 subsections)\n",
      "    ├─ 2.1 Virtualizing the CPU (3,750 chars)\n",
      "    ├─ 2.2 Virtualizing Memory (3,052 chars)\n",
      "    ├─ 2.3 Concurrency (5,386 chars)\n",
      "    ├─ 2.4 Persistence (4,965 chars)\n",
      "    ├─ 2.5 Design Goals (3,919 chars)\n",
      "    ├─ 2.6 Some History (11,916 chars)\n",
      "    ├─ 2.7 Summary (5,596 chars)\n",
      "  • 3 A Dialogue on Virtualization (Part I): 59-60 (2p, 2,285 chars, 0 subsections)\n",
      "  • 4 The Abstraction: The Process (Part I): 61-70 (10p, 18,608 chars, 6 subsections)\n",
      "    ├─ 4.1 The Abstraction: A Process (2,252 chars)\n",
      "    ├─ 4.2 Process API (1,628 chars)\n",
      "    ├─ 4.3 Process Creation: A Little More Detail (3,449 chars)\n",
      "    ├─ 4.4 Process States (1,697 chars)\n",
      "    ├─ 4.5 Data Structures (4,060 chars)\n",
      "    ├─ 4.6 Summary (2,061 chars)\n",
      "  • 5 Interlude: Process API (Part I): 71-80 (10p, 19,141 chars, 6 subsections)\n",
      "    ├─ 5.1 Thefork() System Call (4,566 chars)\n",
      "    ├─ 5.2 Adding wait() System Call (1,360 chars)\n",
      "    ├─ 5.3 Finally, the exec() System Call (2,877 chars)\n",
      "    ├─ 5.4 Why? Motivating the API (6,564 chars)\n",
      "    ├─ 5.5 Other Parts of the API (1,292 chars)\n",
      "    ├─ 5.6 Summary (1,453 chars)\n",
      "  • 6 Mechanism: Limited Direct Execution (Part I): 81-94 (14p, 34,593 chars, 5 subsections)\n",
      "    ├─ 6.1 Basic Technique: Limited Direct Execution (1,980 chars)\n",
      "    ├─ 6.2 Problem #1: Restricted Operations (9,648 chars)\n",
      "    ├─ 6.3 Problem #2: Switching Between Processes (10,566 chars)\n",
      "    ├─ 6.4 Worried About Concurrency? (2,635 chars)\n",
      "    ├─ 6.5 Summary (8,439 chars)\n",
      "  • 7 Scheduling: Introduction (Part I): 95-106 (12p, 25,830 chars, 9 subsections)\n",
      "    ├─ 7.1 Workload Assumptions (1,350 chars)\n",
      "    ├─ 7.2 Scheduling Metrics (1,281 chars)\n",
      "    ├─ 7.3 First In, First Out (FIFO) (3,167 chars)\n",
      "    ├─ 7.4 Shortest Job First (SJF) (2,888 chars)\n",
      "    ├─ 7.5 Shortest Time-to-Completion First (STCF) (3,034 chars)\n",
      "    ├─ 7.6 Round Robin (4,457 chars)\n",
      "    ├─ 7.7 Incorporating I/O (3,253 chars)\n",
      "    ├─ 7.8 No More Oracle (566 chars)\n",
      "    ├─ 7.9 Summary (4,702 chars)\n",
      "  • 8 Scheduling:The Multi-Level Feedback Queue (Part I): 107-118 (12p, 23,348 chars, 6 subsections)\n",
      "    ├─ 8.1 MLFQ: Basic Rules (2,444 chars)\n",
      "    ├─ 8.2 Attempt #1: How to Change Priority (5,593 chars)\n",
      "    ├─ 8.3 Attempt #2: The Priority Boost (2,124 chars)\n",
      "    ├─ 8.4 Attempt #3: Better Accounting (1,491 chars)\n",
      "    ├─ 8.5 Tuning MLFQ And Other Issues (3,499 chars)\n",
      "    ├─ 8.6 MLFQ: Summary (5,847 chars)\n",
      "  • 9 Scheduling: Proportional Share (Part I): 119-128 (10p, 20,180 chars, 7 subsections)\n",
      "    ├─ 9.1 Basic Concept: Tickets Represent Your Share (3,834 chars)\n",
      "    ├─ 9.2 Ticket Mechanisms (2,955 chars)\n",
      "    ├─ 9.3 Implementation (2,088 chars)\n",
      "    ├─ 9.4 An Example (1,321 chars)\n",
      "    ├─ 9.5 How To Assign Tickets? (581 chars)\n",
      "    ├─ 9.6 Why Not Deterministic? (3,862 chars)\n",
      "    ├─ 9.7 Summary (4,491 chars)\n",
      "  • 10 Multiprocessor Scheduling (Advanced) (Part I): 129-140 (12p, 24,645 chars, 7 subsections)\n",
      "    ├─ 10.1 Background: Multiprocessor Architecture (4,725 chars)\n",
      "    ├─ 10.2 Don’t Forget Synchronization (2,882 chars)\n",
      "    ├─ 10.3 One Final Issue: Cache Afﬁnity (879 chars)\n",
      "    ├─ 10.4 Single-Queue Scheduling (3,189 chars)\n",
      "    ├─ 10.5 Multi-Queue Scheduling (5,487 chars)\n",
      "    ├─ 10.6 Linux Multiprocessor Schedulers (1,338 chars)\n",
      "    ├─ 10.7 Summary (3,533 chars)\n",
      "  • 11 Summary Dialogue on CPU Virtualization (Part I): 141-142 (2p, 4,045 chars, 0 subsections)\n",
      "  • 12 A Dialogue on Memory Virtualization (Part I): 143-144 (2p, 3,288 chars, 0 subsections)\n",
      "  • 13 The Abstraction: Address Spaces (Part I): 145-154 (10p, 17,805 chars, 5 subsections)\n",
      "    ├─ 13.1 Early Systems (1,043 chars)\n",
      "    ├─ 13.2 Multiprogramming and Time Sharing (2,842 chars)\n",
      "    ├─ 13.3 The Address Space (4,628 chars)\n",
      "    ├─ 13.4 Goals (4,650 chars)\n",
      "    ├─ 13.5 Summary (4,248 chars)\n",
      "  • 14 Interlude: Memory API (Part I): 155-164 (10p, 18,359 chars, 7 subsections)\n",
      "    ├─ 14.1 Types of Memory (2,177 chars)\n",
      "    ├─ 14.2 Themalloc() Call (4,160 chars)\n",
      "    ├─ 14.3 Thefree() Call (503 chars)\n",
      "    ├─ 14.4 Common Errors (6,884 chars)\n",
      "    ├─ 14.5 Underlying OS Support (1,527 chars)\n",
      "    ├─ 14.6 Other Calls (618 chars)\n",
      "    ├─ 14.7 Summary (2,019 chars)\n",
      "  • 15 Mechanism: Address Translation (Part I): 165-176 (12p, 25,520 chars, 5 subsections)\n",
      "    ├─ 15.1 Assumptions (886 chars)\n",
      "    ├─ 15.2 An Example (4,155 chars)\n",
      "    ├─ 15.3 Dynamic (Hardware-based) Relocation (7,338 chars)\n",
      "    ├─ 15.4 OS Issues (3,512 chars)\n",
      "    ├─ 15.5 Summary (5,958 chars)\n",
      "  • 16 Segmentation (Part I): 177-188 (12p, 23,918 chars, 7 subsections)\n",
      "    ├─ 16.1 Segmentation: Generalized Base/Bounds (3,999 chars)\n",
      "    ├─ 16.2 Which Segment Are We Referring To? (3,169 chars)\n",
      "    ├─ 16.3 What About The Stack? (1,894 chars)\n",
      "    ├─ 16.4 Support for Sharing (1,838 chars)\n",
      "    ├─ 16.5 Fine-grained vs. Coarse-grained Segmentation (1,187 chars)\n",
      "    ├─ 16.6 OS Support (4,052 chars)\n",
      "    ├─ 16.7 Summary (6,440 chars)\n",
      "  • 17 Free-Space Management (Part I): 189-204 (16p, 31,637 chars, 5 subsections)\n",
      "    ├─ 17.1 Assumptions (3,087 chars)\n",
      "    ├─ 17.2 Low-level Mechanisms (13,270 chars)\n",
      "    ├─ 17.3 Basic Strategies (4,325 chars)\n",
      "    ├─ 17.4 Other Approaches (6,329 chars)\n",
      "    ├─ 17.5 Summary (2,619 chars)\n",
      "  • 18 Paging: Introduction (Part I): 205-218 (14p, 25,674 chars, 5 subsections)\n",
      "    ├─ 18.1 Where Are Page Tables Stored? (1,665 chars)\n",
      "    ├─ 18.2 What’s Actually In The Page Table? (3,461 chars)\n",
      "    ├─ 18.3 Paging: Also Too Slow (4,367 chars)\n",
      "    ├─ 18.4 A Memory Trace (5,549 chars)\n",
      "    ├─ 18.5 Summary (4,348 chars)\n",
      "  • 19 Paging: Faster Translations (TLBs) (Part I): 219-236 (18p, 39,859 chars, 8 subsections)\n",
      "    ├─ 19.1 TLB Basic Algorithm (3,253 chars)\n",
      "    ├─ 19.2 Example: Accessing An Array (6,331 chars)\n",
      "    ├─ 19.3 Who Handles The TLB Miss? (6,051 chars)\n",
      "    ├─ 19.4 TLB Contents: What’s In There? (2,408 chars)\n",
      "    ├─ 19.5 TLB Issue: Context Switches (4,565 chars)\n",
      "    ├─ 19.6 Issue: Replacement Policy (1,439 chars)\n",
      "    ├─ 19.7 A Real TLB Entry (3,659 chars)\n",
      "    ├─ 19.8 Summary (10,500 chars)\n",
      "  • 20 Paging: Smaller Tables (Part I): 237-252 (16p, 33,311 chars, 6 subsections)\n",
      "    ├─ 20.1 Simple Solution: Bigger Pages (2,493 chars)\n",
      "    ├─ 20.2 Hybrid Approach: Paging and Segments (6,492 chars)\n",
      "    ├─ 20.3 Multi-level Page Tables (17,351 chars)\n",
      "    ├─ 20.4 Inverted Page Tables (1,022 chars)\n",
      "    ├─ 20.5 Swapping the Page Tables to Disk (675 chars)\n",
      "    ├─ 20.6 Summary (4,098 chars)\n",
      "  • 21 Beyond Physical Memory: Mechanisms (Part I): 253-262 (10p, 22,168 chars, 7 subsections)\n",
      "    ├─ 21.1 Swap Space (2,297 chars)\n",
      "    ├─ 21.2 The Present Bit (3,628 chars)\n",
      "    ├─ 21.3 The Page Fault (2,943 chars)\n",
      "    ├─ 21.4 What If Memory Is Full? (1,935 chars)\n",
      "    ├─ 21.5 Page Fault Control Flow (2,503 chars)\n",
      "    ├─ 21.6 When Replacements Really Occur (2,928 chars)\n",
      "    ├─ 21.7 Summary (2,723 chars)\n",
      "  • 22 Beyond Physical Memory: Policies (Part I): 263-280 (18p, 37,801 chars, 12 subsections)\n",
      "    ├─ 22.1 Cache Management (2,979 chars)\n",
      "    ├─ 22.2 The Optimal Replacement Policy (5,077 chars)\n",
      "    ├─ 22.3 A Simple Policy: FIFO (3,293 chars)\n",
      "    ├─ 22.4 Another Simple Policy: Random (1,458 chars)\n",
      "    ├─ 22.5 Using History: LRU (4,103 chars)\n",
      "    ├─ 22.6 Workload Examples (4,514 chars)\n",
      "    ├─ 22.7 Implementing Historical Algorithms (2,245 chars)\n",
      "    ├─ 22.8 Approximating LRU (2,737 chars)\n",
      "    ├─ 22.9 Considering Dirty Pages (1,013 chars)\n",
      "    ├─ 22.10 Other VM Policies (1,327 chars)\n",
      "    ├─ 22.11 Thrashing (1,463 chars)\n",
      "    ├─ 22.12 Summary (6,463 chars)\n",
      "  • 23 The V AX/VMS Virtual Memory System (Part I): 281-290 (10p, 20,348 chars, 6 subsections)\n",
      "    ├─ 23.1 Background (2,013 chars)\n",
      "    ├─ 23.2 Memory Management Hardware (3,112 chars)\n",
      "    ├─ 23.3 A Real Address Space (3,263 chars)\n",
      "    ├─ 23.4 Page Replacement (4,141 chars)\n",
      "    ├─ 23.5 Other Neat VM Tricks (4,217 chars)\n",
      "    ├─ 23.6 Summary (3,223 chars)\n",
      "  • 24 Summary Dialogue on Memory Virtualization (Part I): 291-296 (6p, 5,378 chars, 0 subsections)\n",
      "  • 25 A Dialogue on Concurrency (Part II): 297-298 (2p, 3,069 chars, 0 subsections)\n",
      "  • 26 Concurrency: An Introduction (Part II): 299-314 (16p, 30,634 chars, 6 subsections)\n",
      "    ├─ 26.1 An Example: Thread Creation (4,711 chars)\n",
      "    ├─ 26.2 Why It Gets Worse: Shared Data (3,351 chars)\n",
      "    ├─ 26.3 The Heart of the Problem: Uncontrolled Scheduling (4,903 chars)\n",
      "    ├─ 26.4 The Wish For Atomicity (3,711 chars)\n",
      "    ├─ 26.5 One More Problem: Waiting For Another (1,091 chars)\n",
      "    ├─ 26.6 Summary: Why in OS Class? (8,921 chars)\n",
      "  • 27 Interlude: Thread API (Part II): 315-326 (12p, 22,504 chars, 6 subsections)\n",
      "    ├─ 27.1 Thread Creation (2,916 chars)\n",
      "    ├─ 27.2 Thread Completion (5,594 chars)\n",
      "    ├─ 27.3 Locks (4,440 chars)\n",
      "    ├─ 27.4 Condition Variables (4,280 chars)\n",
      "    ├─ 27.5 Compiling and Running (596 chars)\n",
      "    ├─ 27.6 Summary (4,032 chars)\n",
      "  • 28 Locks (Part II): 327-346 (20p, 46,153 chars, 17 subsections)\n",
      "    ├─ 28.1 Locks: The Basic Idea (2,692 chars)\n",
      "    ├─ 28.2 Pthread Locks (1,106 chars)\n",
      "    ├─ 28.3 Building A Lock (1,107 chars)\n",
      "    ├─ 28.4 Evaluating Locks (1,441 chars)\n",
      "    ├─ 28.5 Controlling Interrupts (4,638 chars)\n",
      "    ├─ 28.6 Test And Set (Atomic Exchange) (3,838 chars)\n",
      "    ├─ 28.7 Building A Working Spin Lock (3,798 chars)\n",
      "    ├─ 28.8 Evaluating Spin Locks (2,041 chars)\n",
      "    ├─ 28.9 Compare-And-Swap (2,170 chars)\n",
      "    ├─ 28.10 Load-Linked and Store-Conditional (4,106 chars)\n",
      "    ├─ 28.11 Fetch-And-Add (1,983 chars)\n",
      "    ├─ 28.12 Summary: So Much Spinning (1,470 chars)\n",
      "    ├─ 28.13 A Simple Approach: Just Yield, Baby (2,359 chars)\n",
      "    ├─ 28.14 Using Queues: Sleeping Instead Of Spinning (4,752 chars)\n",
      "    ├─ 28.15 Different OS, Different Support (1,718 chars)\n",
      "    ├─ 28.16 Two-Phase Locks (2,003 chars)\n",
      "    ├─ 28.17 Summary (4,294 chars)\n",
      "  • 29 Lock-based Concurrent Data Structures (Part II): 347-360 (14p, 25,894 chars, 5 subsections)\n",
      "    ├─ 29.1 Concurrent Counters (8,804 chars)\n",
      "    ├─ 29.2 Concurrent Linked Lists (6,469 chars)\n",
      "    ├─ 29.3 Concurrent Queues (2,524 chars)\n",
      "    ├─ 29.4 Concurrent Hash Table (2,816 chars)\n",
      "    ├─ 29.5 Summary (4,123 chars)\n",
      "  • 30 Condition Variables (Part II): 361-376 (16p, 31,751 chars, 4 subsections)\n",
      "    ├─ 30.1 Deﬁnition and Routines (6,850 chars)\n",
      "    ├─ 30.2 The Producer/Consumer (Bound Buffer) Problem (16,908 chars)\n",
      "    ├─ 30.3 Covering Conditions (3,383 chars)\n",
      "    ├─ 30.4 Summary (2,484 chars)\n",
      "  • 31 Semaphores (Part II): 377-394 (18p, 36,521 chars, 8 subsections)\n",
      "    ├─ 31.1 Semaphores: A Deﬁnition (3,326 chars)\n",
      "    ├─ 31.2 Binary Semaphores (Locks) (3,672 chars)\n",
      "    ├─ 31.3 Semaphores As Condition Variables (3,968 chars)\n",
      "    ├─ 31.4 The Producer/Consumer (Bounded-Buffer) Problem (8,195 chars)\n",
      "    ├─ 31.5 Reader-Writer Locks (4,633 chars)\n",
      "    ├─ 31.6 The Dining Philosophers (5,341 chars)\n",
      "    ├─ 31.7 How To Implement Semaphores (1,839 chars)\n",
      "    ├─ 31.8 Summary (4,418 chars)\n",
      "  • 32 Common Concurrency Problems (Part II): 395-408 (14p, 27,486 chars, 4 subsections)\n",
      "    ├─ 32.1 What Types Of Bugs Exist? (1,937 chars)\n",
      "    ├─ 32.2 Non-Deadlock Bugs (5,797 chars)\n",
      "    ├─ 32.3 Deadlock Bugs (15,147 chars)\n",
      "    ├─ 32.4 Summary (3,844 chars)\n",
      "  • 33 Event-based Concurrency (Advanced) (Part II): 409-418 (10p, 24,519 chars, 9 subsections)\n",
      "    ├─ 33.1 The Basic Idea: An Event Loop (1,552 chars)\n",
      "    ├─ 33.2 An Important API: select() (orpoll() ) (3,126 chars)\n",
      "    ├─ 33.3 Using select() (1,982 chars)\n",
      "    ├─ 33.4 Why Simpler? No Locks Needed (896 chars)\n",
      "    ├─ 33.5 A Problem: Blocking System Calls (1,694 chars)\n",
      "    ├─ 33.6 A Solution: Asynchronous I/O (5,492 chars)\n",
      "    ├─ 33.7 Another Problem: State Management (2,440 chars)\n",
      "    ├─ 33.8 What Is Still Difﬁcult With Events (2,031 chars)\n",
      "    ├─ 33.9 Summary (3,735 chars)\n",
      "  • 34 Summary Dialogue on Concurrency (Part II): 419-422 (4p, 2,709 chars, 0 subsections)\n",
      "  • 35 A Dialogue on Persistence (Part III): 423-424 (2p, 1,870 chars, 0 subsections)\n",
      "  • 36 I/O Devices (Part III): 425-438 (14p, 27,324 chars, 10 subsections)\n",
      "    ├─ 36.1 System Architecture (1,524 chars)\n",
      "    ├─ 36.2 A Canonical Device (1,348 chars)\n",
      "    ├─ 36.3 The Canonical Protocol (2,379 chars)\n",
      "    ├─ 36.4 Lowering CPU Overhead With Interrupts (4,118 chars)\n",
      "    ├─ 36.5 More Efﬁcient Data Movement With DMA (1,987 chars)\n",
      "    ├─ 36.6 Methods Of Device Interaction (2,037 chars)\n",
      "    ├─ 36.7 Fitting Into The OS: The Device Driver (3,356 chars)\n",
      "    ├─ 36.8 Case Study: A Simple IDE Disk Driver (4,859 chars)\n",
      "    ├─ 36.9 Historical Notes (1,694 chars)\n",
      "    ├─ 36.10 Summary (3,309 chars)\n",
      "  • 37 Hard Disk Drives (Part III): 439-456 (18p, 35,452 chars, 6 subsections)\n",
      "    ├─ 37.1 The Interface (1,501 chars)\n",
      "    ├─ 37.2 Basic Geometry (1,716 chars)\n",
      "    ├─ 37.3 A Simple Disk Drive (8,333 chars)\n",
      "    ├─ 37.4 I/O Time: Doing The Math (6,924 chars)\n",
      "    ├─ 37.5 Disk Scheduling (9,096 chars)\n",
      "    ├─ 37.6 Summary (6,979 chars)\n",
      "  • 38 Redundant Arrays of Inexpensive Disks (RAIDs) (Part III): 457-476 (20p, 46,020 chars, 10 subsections)\n",
      "    ├─ 38.1 Interface And RAID Internals (1,638 chars)\n",
      "    ├─ 38.2 Fault Model (1,241 chars)\n",
      "    ├─ 38.3 How To Evaluate A RAID (1,565 chars)\n",
      "    ├─ 38.4 RAID Level 0: Striping (9,269 chars)\n",
      "    ├─ 38.5 RAID Level 1: Mirroring (7,508 chars)\n",
      "    ├─ 38.6 RAID Level 4: Saving Space With Parity (10,204 chars)\n",
      "    ├─ 38.7 RAID Level 5: Rotating Parity (2,467 chars)\n",
      "    ├─ 38.8 RAID Comparison: A Summary (1,496 chars)\n",
      "    ├─ 38.9 Other Interesting RAID Issues (973 chars)\n",
      "    ├─ 38.10 Summary (5,941 chars)\n",
      "  • 39 Interlude: File and Directories (Part III): 477-496 (20p, 41,485 chars, 16 subsections)\n",
      "    ├─ 39.1 Files and Directories (4,071 chars)\n",
      "    ├─ 39.2 The File System Interface (384 chars)\n",
      "    ├─ 39.3 Creating Files (1,920 chars)\n",
      "    ├─ 39.4 Reading and Writing Files (4,854 chars)\n",
      "    ├─ 39.5 Reading And Writing, But Not Sequentially (2,910 chars)\n",
      "    ├─ 39.6 Writing Immediately with fsync() (2,246 chars)\n",
      "    ├─ 39.7 Renaming Files (1,856 chars)\n",
      "    ├─ 39.8 Getting Information About Files (2,080 chars)\n",
      "    ├─ 39.9 Removing Files (862 chars)\n",
      "    ├─ 39.10 Making Directories (2,413 chars)\n",
      "    ├─ 39.11 Reading Directories (1,613 chars)\n",
      "    ├─ 39.12 Deleting Directories (498 chars)\n",
      "    ├─ 39.13 Hard Links (3,886 chars)\n",
      "    ├─ 39.14 Symbolic Links (2,890 chars)\n",
      "    ├─ 39.15 Making and Mounting a File System (3,032 chars)\n",
      "    ├─ 39.16 Summary (4,382 chars)\n",
      "  • 40 File System Implementation (Part III): 497-514 (18p, 40,804 chars, 8 subsections)\n",
      "    ├─ 40.1 The Way To Think (1,843 chars)\n",
      "    ├─ 40.2 Overall Organization (4,975 chars)\n",
      "    ├─ 40.3 File Organization: The Inode (11,386 chars)\n",
      "    ├─ 40.4 Directory Organization (2,315 chars)\n",
      "    ├─ 40.5 Free Space Management (1,972 chars)\n",
      "    ├─ 40.6 Access Paths: Reading and Writing (8,397 chars)\n",
      "    ├─ 40.7 Caching and Buffering (3,477 chars)\n",
      "    ├─ 40.8 Summary (5,044 chars)\n",
      "  • 41 Locality and The Fast File System (Part III): 515-526 (12p, 24,032 chars, 8 subsections)\n",
      "    ├─ 41.1 The Problem: Poor Performance (2,869 chars)\n",
      "    ├─ 41.2 FFS: Disk Awareness Is The Solution (846 chars)\n",
      "    ├─ 41.3 Organizing Structure: The Cylinder Group (2,834 chars)\n",
      "    ├─ 41.4 Policies: How To Allocate Files and Directories (2,230 chars)\n",
      "    ├─ 41.5 Measuring File Locality (2,945 chars)\n",
      "    ├─ 41.6 The Large-File Exception (4,573 chars)\n",
      "    ├─ 41.7 A Few Other Things About FFS (5,030 chars)\n",
      "    ├─ 41.8 Summary (1,690 chars)\n",
      "  • 42 Crash Consistency: FSCK and Journaling (Part III): 527-546 (20p, 50,549 chars, 5 subsections)\n",
      "    ├─ 42.1 A Detailed Example (7,138 chars)\n",
      "    ├─ 42.2 Solution #1: The File System Checker (5,617 chars)\n",
      "    ├─ 42.3 Solution #2: Journaling (or Write-Ahead Logging) (26,368 chars)\n",
      "    ├─ 42.4 Solution #3: Other Approaches (3,070 chars)\n",
      "    ├─ 42.5 Summary (5,688 chars)\n",
      "  • 43 Log-structured File Systems (Part III): 547-562 (16p, 32,964 chars, 13 subsections)\n",
      "    ├─ 43.1 Writing To Disk Sequentially (1,707 chars)\n",
      "    ├─ 43.2 Writing Sequentially And Effectively (2,369 chars)\n",
      "    ├─ 43.3 How Much To Buffer? (2,165 chars)\n",
      "    ├─ 43.4 Problem: Finding Inodes (1,271 chars)\n",
      "    ├─ 43.5 Solution Through Indirection: The Inode Map (2,457 chars)\n",
      "    ├─ 43.6 The Checkpoint Region (1,417 chars)\n",
      "    ├─ 43.7 Reading A File From Disk: A Recap (1,043 chars)\n",
      "    ├─ 43.8 What About Directories? (2,433 chars)\n",
      "    ├─ 43.9 A New Problem: Garbage Collection (3,929 chars)\n",
      "    ├─ 43.10 Determining Block Liveness (2,184 chars)\n",
      "    ├─ 43.11 A Policy Question: Which Blocks To Clean, And When? (1,219 chars)\n",
      "    ├─ 43.12 Crash Recovery And The Log (2,462 chars)\n",
      "    ├─ 43.13 Summary (5,211 chars)\n",
      "  • 44 Data Integrity and Protection (Part III): 563-574 (12p, 29,478 chars, 9 subsections)\n",
      "    ├─ 44.1 Disk Failure Modes (4,879 chars)\n",
      "    ├─ 44.2 Handling Latent Sector Errors (2,149 chars)\n",
      "    ├─ 44.3 Detecting Corruption: The Checksum (7,533 chars)\n",
      "    ├─ 44.4 Using Checksums (1,306 chars)\n",
      "    ├─ 44.5 A New Problem: Misdirected Writes (2,513 chars)\n",
      "    ├─ 44.6 One Last Problem: Lost Writes (1,770 chars)\n",
      "    ├─ 44.7 Scrubbing (795 chars)\n",
      "    ├─ 44.8 Overheads Of Checksumming (2,270 chars)\n",
      "    ├─ 44.9 Summary (5,387 chars)\n",
      "  • 45 Summary Dialogue on Persistence (Part III): 575-576 (2p, 2,904 chars, 0 subsections)\n",
      "  • 46 A Dialogue on Distribution (Part III): 577-578 (2p, 2,088 chars, 0 subsections)\n",
      "  • 47 Distributed Systems (Part III): 579-594 (16p, 36,436 chars, 6 subsections)\n",
      "    ├─ 47.1 Communication Basics (2,435 chars)\n",
      "    ├─ 47.2 Unreliable Communication Layers (4,156 chars)\n",
      "    ├─ 47.3 Reliable Communication Layers (5,456 chars)\n",
      "    ├─ 47.4 Communication Abstractions (3,769 chars)\n",
      "    ├─ 47.5 Remote Procedure Call (RPC) (14,356 chars)\n",
      "    ├─ 47.6 Summary (2,679 chars)\n",
      "  • 48 Sun’s Network File System (NFS) (Part III): 595-610 (16p, 38,554 chars, 12 subsections)\n",
      "    ├─ 48.1 A Basic Distributed File System (3,218 chars)\n",
      "    ├─ 48.2 On To NFS (762 chars)\n",
      "    ├─ 48.3 Focus: Simple and Fast Server Crash Recovery (765 chars)\n",
      "    ├─ 48.4 Key To Fast Crash Recovery: Statelessness (3,683 chars)\n",
      "    ├─ 48.5 The NFSv2 Protocol (4,989 chars)\n",
      "    ├─ 48.6 From Protocol to Distributed File System (3,447 chars)\n",
      "    ├─ 48.7 Handling Server Failure with Idempotent Operations (5,110 chars)\n",
      "    ├─ 48.8 Improving Performance: Client-side Caching (1,606 chars)\n",
      "    ├─ 48.9 The Cache Consistency Problem (4,435 chars)\n",
      "    ├─ 48.10 Assessing NFS Cache Consistency (1,186 chars)\n",
      "    ├─ 48.11 Implications on Server-Side Write Buffering (4,005 chars)\n",
      "    ├─ 48.12 Summary (3,809 chars)\n",
      "  • 49 The Andrew File System (AFS) (Part III): 611-624 (14p, 31,580 chars, 9 subsections)\n",
      "    ├─ 49.1 AFS Version 1 (3,269 chars)\n",
      "    ├─ 49.2 Problems with Version 1 (3,037 chars)\n",
      "    ├─ 49.3 Improving the Protocol (815 chars)\n",
      "    ├─ 49.4 AFS Version 2 (4,732 chars)\n",
      "    ├─ 49.5 Cache Consistency (4,101 chars)\n",
      "    ├─ 49.6 Crash Recovery (1,983 chars)\n",
      "    ├─ 49.7 Scale And Performance Of AFSv2 (5,913 chars)\n",
      "    ├─ 49.8 AFS: Other Improvements (2,916 chars)\n",
      "    ├─ 49.9 Summary (3,451 chars)\n",
      "  • 50 Summary Dialogue on Distribution (Part III): 625-643 (19p, 27,533 chars, 0 subsections)\n"
     ]
    }
   ],
   "source": [
    "# 결과 요약\n",
    "total_subsections = sum(len(cr.get('subsections', [])) for cr in chapter_ranges)\n",
    "\n",
    "print(\"\\nChapter information:\")\n",
    "for info in chapter_ranges:\n",
    "    part_str = f\"Part {info['part_info']['number']}\" if info['part_info'] else 'Unclassified'\n",
    "    print(f\"  • {info['toc_entry']['full_title']} ({part_str}): {info['start_page']}-{info['end_page']} \"\n",
    "        f\"({info['page_count']}p, {len(info['text']):,} chars, {len(info.get('subsections', []))} subsections)\")\n",
    "    \n",
    "    # 서브섹션 정보 출력\n",
    "    if info.get('subsections'):\n",
    "        for subsection in info['subsections']:\n",
    "            print(f\"    ├─ {subsection['toc_entry']['number']} {subsection['toc_entry']['title']} ({len(subsection['text']):,} chars)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
