{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c95d94b",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 4: OSTEP 벡터 인덱스 구축 (FAISS HNSW)\n",
    "\n",
    "OSTEP 임베딩 벡터로 HNSW 인덱스를 생성/저장하고 검색 품질을 검증합니다.\n",
    "\n",
    "## 📚 학습 목표\n",
    "- HNSW 인덱스 구성요소와 핵심 파라미터(M/efConstruction/efSearch) 이해\n",
    "- 인덱스 저장/로드 파이프라인 구현 및 활용법 학습\n",
    "- 인덱스 품질 검증을 위한 간단한 검색/점수화 루틴 작성\n",
    "\n",
    "## 📋 실습 구성\n",
    "- 1️⃣ 환경 설정: 패키지 설치, 경로/상수 정의\n",
    "- 2️⃣ 데이터 로드: 임베딩/청크 로드 및 일치성 검증\n",
    "- 3️⃣ Ground Truth: 브루트포스로 참값 생성/저장\n",
    "- 4️⃣ 인덱스 구축/저장: HNSW 생성, 파라미터 적용, 파일 저장\n",
    "- 5️⃣ 검증: 저장된 인덱스 로드 후 쿼리 검색 테스트\n",
    "- 6️⃣ 파라미터 실험(선택): 성능 변화 관찰\n",
    "\n",
    "> ⚠️ 인덱스 크기/메모리 사용량과 파라미터에 따른 속도·정확도 trade-off를 고려하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb28b889",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣ Google Colab 환경 설정\n",
    "\n",
    "이 노트북은 **Google Colab에서 GPU를 사용**하여 실행하도록 설계되었습니다.\n",
    "\n",
    "### 📌 실행 전 준비사항\n",
    "1. **런타임 유형 설정**: 메뉴에서 `런타임` → `런타임 유형 변경` → `GPU` 선택\n",
    "2. **첫 번째 코드 셀 실행**: Google Drive 마운트 및 필수 패키지 자동 설치\n",
    "3. **사전 실행 필요**: chapter.2 (전처리), chapter.3 (임베딩) 완료\n",
    "\n",
    "> ⚠️ **중요**: GPU를 사용하면 벡터 인덱스 구축 및 검색 속도가 향상됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fbc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Google Colab 환경 설정\n",
    "# ========================================\n",
    "from google.colab import drive\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Google Drive 마운트\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 필요 패키지 설치\n",
    "!pip -q install faiss-cpu sentence-transformers numpy\n",
    "\n",
    "# 경고 억제\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 라이브러리 임포트\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# GPU 자동 감지\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"🔧 Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# 경로 설정\n",
    "BASE_DIR = \"/content/drive/MyDrive/ostep_rag\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "EMBEDDINGS_FILE = os.path.join(DATA_DIR, \"vector\", \"ostep_tok400_ov20_embeddings.npy\")\n",
    "CHUNK_FILE = os.path.join(DATA_DIR, \"chunk\", \"ostep_tok400_ov20.json\")\n",
    "OUTPUT_DIR = os.path.join(DATA_DIR, \"index\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# HNSW 파라미터\n",
    "M = 32  # 각 노드당 최대 연결 수\n",
    "EF_CONSTRUCTION = 200  # 인덱스 구축 시 탐색 범위\n",
    "EF_SEARCH = 40\n",
    "\n",
    "print(\"\\n✅ 환경 설정 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed026de4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2️⃣ 데이터 로드\n",
    "\n",
    "이 셀에서는 chapter.3에서 생성한 임베딩 벡터와 메타데이터를 로드합니다.\n",
    "\n",
    "**주요 내용:**\n",
    "- NumPy 배열로 저장된 임베딩 벡터 로드\n",
    "- JSON 파일로 저장된 메타데이터 로드\n",
    "- 데이터 shape 및 구조 확인\n",
    "\n",
    "**실행 결과:**\n",
    "- 임베딩 벡터와 메타데이터가 성공적으로 로드되고 개수가 출력됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 벡터 로드\n",
    "print(f\"Loading embeddings from: {EMBEDDINGS_FILE}\")\n",
    "embeddings = np.load(EMBEDDINGS_FILE)\n",
    "print(f\"✓ Embeddings loaded: {embeddings.shape}\")\n",
    "print(f\"  Dtype: {embeddings.dtype}\")\n",
    "\n",
    "# 원본 chunk 파일 로드 (메타데이터 대신 원본 JSON 사용)\n",
    "print(f\"\\nLoading chunks from: {CHUNK_FILE}\")\n",
    "with open(CHUNK_FILE, 'r', encoding='utf-8') as f:\n",
    "    chunks = json.load(f)\n",
    "print(f\"✓ Chunks loaded: {len(chunks)} entries\")\n",
    "\n",
    "# 데이터 일치 확인\n",
    "assert len(embeddings) == len(chunks), \\\n",
    "    f\"Mismatch: {len(embeddings)} embeddings vs {len(chunks)} chunks\"\n",
    "print(f\"✓ Data consistency verified\")\n",
    "\n",
    "# 샘플 chunk 출력\n",
    "print(\"\\nSample chunk (first entry):\")\n",
    "sample = chunks[0]\n",
    "for key, value in sample.items():\n",
    "    if key == 'text':\n",
    "        print(f\"  {key}: {value[:100]}...\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nTotal vectors to index: {len(embeddings)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f92d6",
   "metadata": {},
   "source": [
    "---\n",
    "## 3️⃣ Ground Truth 생성\n",
    "\n",
    "이 셀에서는 테스트 쿼리에 대한 정확한 답변(Ground Truth)을 생성합니다.\n",
    "\n",
    "**주요 내용:**\n",
    "- 50개의 테스트 쿼리 로드\n",
    "- Brute-force 검색(IndexFlatL2)으로 각 쿼리의 정확한 top-10 결과 생성\n",
    "- Ground truth를 파일로 저장하여 이후 실험에서 재사용\n",
    "\n",
    "**실행 결과:**\n",
    "- Ground truth 파일이 생성되고 저장됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "\n",
    "# Ground Truth 생성 설정\n",
    "QUERIES_FILE = \"../data/documents/test_queries.json\"\n",
    "GT_FILE = Path(OUTPUT_DIR) / \"ostep_queries_gt_k10.npy\"\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "d=384\n",
    "K = 10  # top-k 결과 저장\n",
    "\n",
    "print(f\"Loading test queries from: {QUERIES_FILE}\")\n",
    "with open(QUERIES_FILE, 'r', encoding='utf-8') as f:\n",
    "    test_queries = json.load(f)\n",
    "print(f\"✓ Loaded {len(test_queries)} test queries\\n\")\n",
    "\n",
    "# 모델 로드\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "model = SentenceTransformer(MODEL_NAME, device=\"cpu\")\n",
    "print(\"✓ Model loaded\\n\")\n",
    "\n",
    "# 쿼리 임베딩 생성\n",
    "print(\"Generating query embeddings...\")\n",
    "query_embeddings = model.encode(test_queries, convert_to_numpy=True, normalize_embeddings=True)\n",
    "print(f\"✓ Query embeddings generated: {query_embeddings.shape}\\n\")\n",
    "\n",
    "# Brute-force 인덱스 생성 (정확한 검색을 위한)\n",
    "print(\"Building brute-force index for ground truth...\")\n",
    "gt_index = faiss.IndexFlatL2(d)\n",
    "gt_index.add(embeddings.astype('float32'))\n",
    "print(f\"✓ Brute-force index built: {gt_index.ntotal} vectors\\n\")\n",
    "\n",
    "# Ground Truth 검색\n",
    "print(f\"Searching ground truth for top-{K} results...\")\n",
    "gt_distances, gt_indices = gt_index.search(query_embeddings.astype('float32'), K)\n",
    "print(f\"✓ Ground truth search completed: {gt_indices.shape}\\n\")\n",
    "\n",
    "# Ground Truth 저장\n",
    "print(f\"Saving ground truth to: {GT_FILE}\")\n",
    "np.save(str(GT_FILE), gt_indices)\n",
    "print(f\"✓ Ground truth saved: {GT_FILE}\")\n",
    "\n",
    "# ∃ 샘플 출력\n",
    "print(\"\\nSample ground truth (first query):\")\n",
    "print(f\"  Query: {test_queries[0][:80]}...\")\n",
    "print(f\"  Top-3 indices: {gt_indices[0][:3]}\")\n",
    "print(f\"  Top-3 chunks:\")\n",
    "for i, idx in enumerate(gt_indices[0][:3]):\n",
    "    chunk = chunks[idx]\n",
    "    print(f\"    {i+1}. [{chunk['chapter_title']}] {chunk['text'][:60]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e81f8",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5eb30",
   "metadata": {},
   "source": [
    "---\n",
    "## 3️⃣ 인덱스 구축\n",
    "\n",
    "이 셀에서는 FAISS HNSW 인덱스를 생성하고 벡터를 추가합니다.\n",
    "\n",
    "**주요 내용:**\n",
    "- HNSW32 인덱스 생성 (M=32, 각 노드당 최대 32개 연결)\n",
    "- efConstruction 파라미터 설정\n",
    "- 정규화된 벡터 추가 (L2 distance가 코사인 유사도와 동일)\n",
    "\n",
    "**실행 결과:**\n",
    "- 인덱스가 생성되고 모든 벡터가 추가됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf9ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = embeddings.shape[1]  # 벡터 차원\n",
    "print(f\"Vector dimension: {d}\")\n",
    "print(f\"\\nBuilding HNSW{M} index...\")\n",
    "\n",
    "# HNSW 인덱스 생성 (올바른 형식: \"HNSW32\")\n",
    "index = faiss.index_factory(d, f\"HNSW{M}\")\n",
    "\n",
    "# 인덱스 품질 파라미터 설정\n",
    "faiss.ParameterSpace().set_index_parameter(index, \"efConstruction\", EF_CONSTRUCTION)\n",
    "faiss.ParameterSpace().set_index_parameter(index, \"efSearch\", EF_SEARCH)\n",
    "\n",
    "print(f\"✓ Index created: {index}\")\n",
    "print(f\"  efConstruction: {EF_CONSTRUCTION}\")\n",
    "print(f\"  efSearch: {EF_SEARCH}\")\n",
    "\n",
    "# 벡터 추가 (float32로 변환)\n",
    "print(f\"\\nAdding {len(embeddings)} vectors to index...\")\n",
    "index.add(embeddings.astype('float32'))\n",
    "\n",
    "print(f\"✓ Index built successfully!\")\n",
    "print(f\"  Total vectors indexed: {index.ntotal}\")\n",
    "print(f\"  Is trained: {index.is_trained}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca2fa54",
   "metadata": {},
   "source": [
    "---\n",
    "## 4️⃣ 인덱스 저장\n",
    "\n",
    "이 셀에서는 생성된 인덱스를 파일로 저장합니다.\n",
    "\n",
    "**주요 내용:**\n",
    "- FAISS 인덱스 파일(.index) 저장\n",
    "- 인덱스 메타정보 JSON 파일 저장\n",
    "\n",
    "**실행 결과:**\n",
    "- 인덱스 파일이 생성되고 저장 경로가 출력됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 파일 경로 설정\n",
    "INDEX_FILE = Path(OUTPUT_DIR) / \"ostep_hnsw.index\"\n",
    "METADATA_INDEX_FILE = Path(OUTPUT_DIR) / \"ostep_hnsw_metadata.json\"\n",
    "\n",
    "# FAISS 인덱스 저장\n",
    "print(f\"Saving index to: {INDEX_FILE}\")\n",
    "faiss.write_index(index, str(INDEX_FILE))\n",
    "print(f\"✓ Index saved: {INDEX_FILE}\")\n",
    "\n",
    "# 인덱스 메타정보 저장\n",
    "index_info = {\n",
    "    'index_type': f'HNSW{M}',\n",
    "    'num_vectors': index.ntotal,\n",
    "    'vector_dim': d,\n",
    "    'ef_construction': EF_CONSTRUCTION,\n",
    "    'ef_search': EF_SEARCH,\n",
    "    'is_trained': index.is_trained,\n",
    "    'embeddings_source': str(EMBEDDINGS_FILE)\n",
    "}\n",
    "\n",
    "print(f\"\\nSaving index metadata to: {METADATA_INDEX_FILE}\")\n",
    "with open(METADATA_INDEX_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(index_info, f, ensure_ascii=False, indent=2)\n",
    "print(f\"✓ Index metadata saved\")\n",
    "\n",
    "# 파일 크기 확인\n",
    "index_size = INDEX_FILE.stat().st_size / (1024 * 1024)  # MB\n",
    "\n",
    "print(f\"\\nFile sizes:\")\n",
    "print(f\"  Index: {index_size:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49354b27",
   "metadata": {},
   "source": [
    "---\n",
    "## 5️⃣ 검증 - 인덱스 로드 및 쿼리 검색\n",
    "\n",
    "이 셀에서는 저장된 인덱스를 로드하고 실제 쿼리로 검색합니다.\n",
    "\n",
    "**주요 내용:**\n",
    "- SentenceTransformer 모델 로드\n",
    "- 저장된 인덱스 로드\n",
    "- 사용자가 입력한 쿼리 문장으로 검색\n",
    "- 검색 결과 표시\n",
    "\n",
    "**사용 방법:**\n",
    "- `query_text` 변수에 검색할 문장을 입력하세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SentenceTransformer 모델 로드\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "device = \"cpu\"\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "model = SentenceTransformer(MODEL_NAME, device=device)\n",
    "print(\"✓ Model loaded successfully!\")\n",
    "\n",
    "# 2. 저장된 인덱스 로드\n",
    "print(\"\\nLoading saved index...\")\n",
    "loaded_index = faiss.read_index(str(INDEX_FILE))\n",
    "print(f\"✓ Index loaded successfully!\")\n",
    "print(f\"  Total vectors: {loaded_index.ntotal}\")\n",
    "print(f\"  Is trained: {loaded_index.is_trained}\")\n",
    "\n",
    "# 3. 메타데이터 로드\n",
    "with open(METADATA_INDEX_FILE, 'r', encoding='utf-8') as f:\n",
    "    loaded_index_info = json.load(f)\n",
    "\n",
    "print(\"\\nIndex metadata:\")\n",
    "for key, value in loaded_index_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 4. 검색할 쿼리 문장 입력\n",
    "query_text = \"How does the operating system handle memory virtualization?\"  # 여기에 검색할 문장을 입력하세요\n",
    "k = 5  # top-k 검색\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Query: {query_text}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 5. 쿼리를 임베딩으로 변환\n",
    "print(f\"\\nEmbedding query text...\")\n",
    "query_embedding = model.encode([query_text], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "print(f\"✓ Query embedded: {query_embedding.shape}\")\n",
    "\n",
    "# 6. FAISS 인덱스에서 검색\n",
    "print(f\"\\nSearching for top-{k} nearest neighbors...\")\n",
    "D, I = loaded_index.search(query_embedding.reshape(1, -1).astype('float32'), k)\n",
    "\n",
    "# 7. 거리를 유사도 점수로 변환 (정규화된 벡터의 L2 거리)\n",
    "# similarity ≈ 1 - (distance/2)\n",
    "scores = 1 - (D[0] / 2)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Top-{k} Search Results:\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for rank, (idx, score) in enumerate(zip(I[0], scores), 1):\n",
    "    chunk = chunks[idx]\n",
    "    # print(f\"Rank {rank} (Score: {score:.4f}):\")\n",
    "    # print(f\"  chunk ID: {chunk['chunk_id']}\")\n",
    "    # print(f\"  Chapter: {chunk['chapter_title']}\")\n",
    "    # if chunk.get('subsection_title'):\n",
    "    #     print(f\"  Section: {chunk['subsection_title']}\")\n",
    "    \n",
    "    # 원본 텍스트 표시\n",
    "    text_preview = chunk['text'][:70] if chunk.get('text') else 'N/A'\n",
    "    print(f\"Rank {rank}: {text_preview}...\")\n",
    "\n",
    "print(\"✓ Search completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce35284",
   "metadata": {},
   "source": [
    "---\n",
    "## 6️⃣ HNSW 파라미터 실험\n",
    "\n",
    "이 셀에서는 HNSW 파라미터(M, efConstruction, efSearch) 변화에 따른 성능을 측정합니다.\n",
    "\n",
    "**측정 지표:**\n",
    "- 인덱스 구축 시간 (초)\n",
    "- 검색 속도 (평균 latency, ms)\n",
    "- 검색 정확도 (Recall@10)\n",
    "\n",
    "**파라미터 범위:**\n",
    "- M: [8, 16, 32, 48, 64]\n",
    "- efConstruction: [50, 100, 200, 300, 400, 500]\n",
    "- efSearch: [10, 20, 40, 80, 160, 320]\n",
    "\n",
    "⚠️ **주의:** 이 실험은 많은 파라미터 조합을 테스트하므로 실행 시간이 오래 걸릴 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89aed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험 파라미터 정의\n",
    "M_VALUES = [8, 16, 32, 48, 64]\n",
    "EF_CONSTRUCTION_VALUES = [50, 100, 200, 300, 400, 500]\n",
    "EF_SEARCH_VALUES = [10, 20, 40, 80, 160, 320]\n",
    "\n",
    "# Ground Truth 로드\n",
    "print(\"Loading ground truth...\")\n",
    "gt_indices = np.load(str(GT_FILE))\n",
    "print(f\"✓ Ground truth loaded: {gt_indices.shape}\\n\")\n",
    "\n",
    "# 실험 결과 저장용\n",
    "results = []\n",
    "\n",
    "# 총 조합 수 계산\n",
    "total_combinations = len(M_VALUES) * len(EF_CONSTRUCTION_VALUES) * len(EF_SEARCH_VALUES)\n",
    "print(f\"Total parameter combinations to test: {total_combinations}\")\n",
    "print(f\"Testing {len(test_queries)} queries per combination...\\n\")\n",
    "\n",
    "current = 0\n",
    "for m_val in M_VALUES:\n",
    "    for ef_cons_val in EF_CONSTRUCTION_VALUES:\n",
    "        for ef_search_val in EF_SEARCH_VALUES:\n",
    "            current += 1\n",
    "            print(f\"[{current}/{total_combinations}] M={m_val}, efConstruction={ef_cons_val}, efSearch={ef_search_val}\")\n",
    "            \n",
    "            try:\n",
    "                # 1. 인덱스 구축\n",
    "                start_time = time.time()\n",
    "                test_index = faiss.index_factory(d, f\"HNSW{m_val}\")\n",
    "                faiss.ParameterSpace().set_index_parameter(test_index, \"efConstruction\", ef_cons_val)\n",
    "                faiss.ParameterSpace().set_index_parameter(test_index, \"efSearch\", ef_search_val)\n",
    "                test_index.add(embeddings.astype('float32'))\n",
    "                build_time = time.time() - start_time\n",
    "                \n",
    "                # 2. 검색 성능 측정\n",
    "                # efSearch 파라미터를 설정\n",
    "                faiss.ParameterSpace().set_index_parameter(test_index, \"efSearch\", ef_search_val)\n",
    "                \n",
    "                search_latencies = []\n",
    "                all_predicted_indices = []\n",
    "                \n",
    "                for query_emb in query_embeddings:\n",
    "                    start = time.time()\n",
    "                    _, indices = test_index.search(query_emb.reshape(1, -1).astype('float32'), K)\n",
    "                    latency = (time.time() - start) * 1000  # ms\n",
    "                    search_latencies.append(latency)\n",
    "                    all_predicted_indices.append(indices[0])\n",
    "                \n",
    "                avg_latency = np.mean(search_latencies)\n",
    "                \n",
    "                # 3. Recall@10 계산\n",
    "                recall_scores = []\n",
    "                for gt_idx, pred_idx in zip(gt_indices, all_predicted_indices):\n",
    "                    recall = len(set(gt_idx) & set(pred_idx)) / len(gt_idx)\n",
    "                    recall_scores.append(recall)\n",
    "                \n",
    "                mean_recall = np.mean(recall_scores)\n",
    "                \n",
    "                # 결과 저장\n",
    "                results.append({\n",
    "                    'M': m_val,\n",
    "                    'efConstruction': ef_cons_val,\n",
    "                    'efSearch': ef_search_val,\n",
    "                    'build_time': build_time,\n",
    "                    'avg_latency_ms': avg_latency,\n",
    "                    'recall@10': mean_recall\n",
    "                })\n",
    "                \n",
    "                print(f\"  → Build: {build_time:.3f}s, Latency: {avg_latency:.3f}ms, Recall@10: {mean_recall:.4f}\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Error: {str(e)}\\n\")\n",
    "\n",
    "print(\"✓ All experiments completed!\")\n",
    "print(f\"Total results: {len(results)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e86162",
   "metadata": {},
   "source": [
    "---\n",
    "## 7️⃣ 실험 결과 저장 및 요약\n",
    "\n",
    "실험 결과를 파일로 저장하고 요약 통계를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437702f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 DataFrame으로 변환\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# 결과 저장\n",
    "RESULTS_FILE = Path(OUTPUT_DIR) / \"hnsw_experiment_results.json\"\n",
    "print(f\"Saving results to: {RESULTS_FILE}\")\n",
    "df_results.to_json(RESULTS_FILE, orient='records', indent=2)\n",
    "print(f\"✓ Results saved\\n\")\n",
    "\n",
    "# 요약 통계 출력\n",
    "print(\"=\"*70)\n",
    "print(\"Experiment Summary Statistics\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal configurations tested: {len(df_results)}\")\n",
    "print(f\"\\nMetrics Summary:\")\n",
    "print(f\"  Build Time: {df_results['build_time'].mean():.3f}s ± {df_results['build_time'].std():.3f}s\")\n",
    "print(f\"    Min: {df_results['build_time'].min():.3f}s\")\n",
    "print(f\"    Max: {df_results['build_time'].max():.3f}s\")\n",
    "print(f\"\\n  Search Latency: {df_results['avg_latency_ms'].mean():.3f}ms ± {df_results['avg_latency_ms'].std():.3f}ms\")\n",
    "print(f\"    Min: {df_results['avg_latency_ms'].min():.3f}ms\")\n",
    "print(f\"    Max: {df_results['avg_latency_ms'].max():.3f}ms\")\n",
    "print(f\"\\n  Recall@10: {df_results['recall@10'].mean():.4f} ± {df_results['recall@10'].std():.4f}\")\n",
    "print(f\"    Min: {df_results['recall@10'].min():.4f}\")\n",
    "print(f\"    Max: {df_results['recall@10'].max():.4f}\")\n",
    "\n",
    "# Best configurations\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Best Configurations by Metric\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nFastest Build Time:\")\n",
    "best_build = df_results.loc[df_results['build_time'].idxmin()]\n",
    "print(f\"  M={best_build['M']}, efConstruction={best_build['efConstruction']}, efSearch={best_build['efSearch']}\")\n",
    "print(f\"  Build: {best_build['build_time']:.3f}s, Latency: {best_build['avg_latency_ms']:.3f}ms, Recall@10: {best_build['recall@10']:.4f}\")\n",
    "\n",
    "print(\"\\nFastest Search:\")\n",
    "best_latency = df_results.loc[df_results['avg_latency_ms'].idxmin()]\n",
    "print(f\"  M={best_latency['M']}, efConstruction={best_latency['efConstruction']}, efSearch={best_latency['efSearch']}\")\n",
    "print(f\"  Build: {best_latency['build_time']:.3f}s, Latency: {best_latency['avg_latency_ms']:.3f}ms, Recall@10: {best_latency['recall@10']:.4f}\")\n",
    "\n",
    "print(\"\\nBest Recall@10:\")\n",
    "best_recall = df_results.loc[df_results['recall@10'].idxmax()]\n",
    "print(f\"  M={best_recall['M']}, efConstruction={best_recall['efConstruction']}, efSearch={best_recall['efSearch']}\")\n",
    "print(f\"  Build: {best_recall['build_time']:.3f}s, Latency: {best_recall['avg_latency_ms']:.3f}ms, Recall@10: {best_recall['recall@10']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b57b6",
   "metadata": {},
   "source": [
    "---\n",
    "## 8️⃣ 파라미터별 성능 시각화\n",
    "\n",
    "파라미터 변화에 따른 성능 변화를 시각화합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 시각화 하이퍼파라미터\n",
    "FIGSIZE_M = (18, 5)\n",
    "FIGSIZE_EFCONS = (18, 5)\n",
    "FIGSIZE_EFSEARCH = (12, 5)\n",
    "RECALL_YMIN, RECALL_YMAX = 0.9, 1.003\n",
    "\n",
    "# 1) M 별 Figure (Build, Latency, Recall@10)\n",
    "fig_m, axes_m = plt.subplots(1, 3, figsize=FIGSIZE_M)\n",
    "fig_m.suptitle('Effect of M on Performance', fontsize=16, fontweight='bold')\n",
    "\n",
    "# M vs Build Time\n",
    "m_build_avg = df_results.groupby('M')['build_time'].mean()\n",
    "axes_m[0].plot(m_build_avg.index, m_build_avg.values, marker='o', linewidth=2, markersize=8)\n",
    "axes_m[0].set_xlabel('M (Max connections)', fontsize=12)\n",
    "axes_m[0].set_ylabel('Build Time (s)', fontsize=12)\n",
    "axes_m[0].set_title('M vs Build Time', fontsize=13, fontweight='bold')\n",
    "axes_m[0].grid(True, alpha=0.3)\n",
    "\n",
    "# M vs Latency\n",
    "m_latency_avg = df_results.groupby('M')['avg_latency_ms'].mean()\n",
    "axes_m[1].plot(m_latency_avg.index, m_latency_avg.values, marker='o', linewidth=2, markersize=8, color='orange')\n",
    "axes_m[1].set_xlabel('M (Max connections)', fontsize=12)\n",
    "axes_m[1].set_ylabel('Avg Latency (ms)', fontsize=12)\n",
    "axes_m[1].set_title('M vs Search Latency', fontsize=13, fontweight='bold')\n",
    "axes_m[1].grid(True, alpha=0.3)\n",
    "\n",
    "# M vs Recall@10\n",
    "m_recall_avg = df_results.groupby('M')['recall@10'].mean()\n",
    "axes_m[2].plot(m_recall_avg.index, m_recall_avg.values, marker='o', linewidth=2, markersize=8, color='green')\n",
    "axes_m[2].set_xlabel('M (Max connections)', fontsize=12)\n",
    "axes_m[2].set_ylabel('Recall@10', fontsize=12)\n",
    "axes_m[2].set_title('M vs Recall@10', fontsize=13, fontweight='bold')\n",
    "axes_m[2].grid(True, alpha=0.3)\n",
    "axes_m[2].set_ylim(RECALL_YMIN, RECALL_YMAX)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) efConstruction 별 Figure (Build, Recall@10)\n",
    "fig_ec, axes_ec = plt.subplots(1, 3, figsize=FIGSIZE_EFCONS)\n",
    "fig_ec.suptitle('Effect of efConstruction on Performance', fontsize=16, fontweight='bold')\n",
    "\n",
    "ef_cons_build_avg = df_results.groupby('efConstruction')['build_time'].mean()\n",
    "axes_ec[0].plot(ef_cons_build_avg.index, ef_cons_build_avg.values, marker='s', linewidth=2, markersize=8)\n",
    "axes_ec[0].set_xlabel('efConstruction', fontsize=12)\n",
    "axes_ec[0].set_ylabel('Build Time (s)', fontsize=12)\n",
    "axes_ec[0].set_title('efConstruction vs Build Time', fontsize=13, fontweight='bold')\n",
    "axes_ec[0].grid(True, alpha=0.3)\n",
    "\n",
    "ef_cons_latency_avg = df_results.groupby('efConstruction')['avg_latency_ms'].mean()\n",
    "axes_ec[1].plot(ef_cons_latency_avg.index, ef_cons_latency_avg.values, marker='o', linewidth=2, markersize=8, color='orange')\n",
    "axes_ec[1].set_xlabel('efConstruction', fontsize=12)\n",
    "axes_ec[1].set_ylabel('Avg Latency (ms)', fontsize=12)\n",
    "axes_ec[1].set_title('efConstruction vs Search Latency', fontsize=13, fontweight='bold')\n",
    "axes_ec[1].grid(True, alpha=0.3)\n",
    "axes_ec[1].set_ylim(0.06, 0.08)\n",
    "\n",
    "ef_cons_recall_avg = df_results.groupby('efConstruction')['recall@10'].mean()\n",
    "axes_ec[2].plot(ef_cons_recall_avg.index, ef_cons_recall_avg.values, marker='s', linewidth=2, markersize=8, color='green')\n",
    "axes_ec[2].set_xlabel('efConstruction', fontsize=12)\n",
    "axes_ec[2].set_ylabel('Recall@10', fontsize=12)\n",
    "axes_ec[2].set_title('efConstruction vs Recall@10', fontsize=13, fontweight='bold')\n",
    "axes_ec[2].grid(True, alpha=0.3)\n",
    "axes_ec[2].set_ylim(RECALL_YMIN, RECALL_YMAX)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) efSearch 별 Figure (Latency, Recall@10)\n",
    "fig_es, axes_es = plt.subplots(1, 2, figsize=FIGSIZE_EFSEARCH)\n",
    "fig_es.suptitle('Effect of efSearch on Performance', fontsize=16, fontweight='bold')\n",
    "\n",
    "# efSearch vs Latency\n",
    "ef_search_latency = df_results.groupby('efSearch')['avg_latency_ms'].mean()\n",
    "axes_es[0].plot(ef_search_latency.index, ef_search_latency.values, marker='D', linewidth=2, markersize=8, color='red')\n",
    "axes_es[0].set_xlabel('efSearch', fontsize=12)\n",
    "axes_es[0].set_ylabel('Avg Latency (ms)', fontsize=12)\n",
    "axes_es[0].set_title('efSearch vs Search Latency', fontsize=13, fontweight='bold')\n",
    "axes_es[0].grid(True, alpha=0.3)\n",
    "\n",
    "# efSearch vs Recall@10\n",
    "ef_search_recall = df_results.groupby('efSearch')['recall@10'].mean()\n",
    "axes_es[1].plot(ef_search_recall.index, ef_search_recall.values, marker='D', linewidth=2, markersize=8, color='purple')\n",
    "axes_es[1].set_xlabel('efSearch', fontsize=12)\n",
    "axes_es[1].set_ylabel('Recall@10', fontsize=12)\n",
    "axes_es[1].set_title('efSearch vs Recall@10', fontsize=13, fontweight='bold')\n",
    "axes_es[1].grid(True, alpha=0.3)\n",
    "axes_es[1].set_ylim(RECALL_YMIN, RECALL_YMAX)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
